{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This next cell contains methods for generating data for training the feature extractor and data for environments 1, 2, and 3 by adding color to the MNIST images and binarizing the image labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch import nn, optim, autograd\n",
    "import pandas as pd\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Download and split the data\n",
    "mnist = datasets.MNIST('~/datasets/mnist', train=True, download=True)\n",
    "mnist_train = (mnist.data[:40000], mnist.targets[:40000])\n",
    "mnist_test = (mnist.data[40000:], mnist.targets[40000:])\n",
    "mnist_all = (mnist.data, mnist.targets)\n",
    "\n",
    "#Shuffle the data\n",
    "rng_state = np.random.get_state()\n",
    "np.random.shuffle(mnist_train[0].numpy())\n",
    "np.random.set_state(rng_state)\n",
    "np.random.shuffle(mnist_train[1].numpy())\n",
    "\n",
    "rng_state = np.random.get_state()\n",
    "np.random.shuffle(mnist_all[0].numpy())\n",
    "np.random.set_state(rng_state)\n",
    "np.random.shuffle(mnist_all[1].numpy())\n",
    "\n",
    "# Splitting the data that will be used to train the feature extractor \n",
    "# into 80% train set and 20% test set\n",
    "X_train = mnist_all[0][:int(0.8*len(mnist_all[0]))] \n",
    "y_train = mnist_all[1][:int(0.8*len(mnist_all[1]))] \n",
    "X_test = mnist_all[0][int(0.8*len(mnist_all[0])):]\n",
    "y_test = mnist_all[1][int(0.8*len(mnist_all[1])):]\n",
    "\n",
    "\n",
    "# used to binarize the target variable\n",
    "def binarize(y, label_noise=0.):\n",
    "    \n",
    "    y = np.copy(y) > 4\n",
    "    \n",
    "    if label_noise > 0:\n",
    "        y = np.logical_xor(y, np.random.binomial(1, label_noise, size=len(y)))\n",
    "    \n",
    "    return y.astype(int)\n",
    "\n",
    "# used to randomly add color to the dataset used to train the feature extractor\n",
    "def color_digits(X, y, color_noise=None, downsample=True):    \n",
    "    if downsample:\n",
    "        X = np.copy(X)[:,::2,::2]\n",
    "    \n",
    "    if color_noise is None:\n",
    "        color = np.random.choice([True, False], size=len(y))\n",
    "    else:\n",
    "        color = np.logical_xor(y, np.random.binomial(1, color_noise, size=len(y)))\n",
    "    colored_X = np.repeat(X[:,None,:,:],2,axis=1)\n",
    "    colored_X[color,0,:,:] = 0\n",
    "    colored_X[~color,1,:,:] = 0    \n",
    "    colored_X = colored_X.reshape(X.shape[0],-1)    \n",
    "    return (colored_X.astype(float)/ 255.), color.astype(int)\n",
    "\n",
    "# Used to generate environments 1, 2, and 3 by varying the distribution of color\n",
    "def generate_environments(X, y, color_noise=None, downsample=True):    \n",
    "    if downsample:\n",
    "        X = np.copy(X)[:,::2,::2]\n",
    "    \n",
    "    if color_noise is None:\n",
    "        color = np.random.choice([True, False], size=len(y))\n",
    "    else:\n",
    "        color = np.logical_xor(y, np.random.binomial(1, color_noise, size=len(y)))\n",
    "    colored_X = np.repeat(X[:,None,:,:],2,axis=1)\n",
    "    colored_X[color,0,:,:] = 0\n",
    "    colored_X[~color,1,:,:] = 0\n",
    "    \n",
    "    colored_X = colored_X.reshape(X.shape[0],-1)\n",
    "    \n",
    "    return {\n",
    "      'images': (colored_X.astype(float) / 255.),\n",
    "      'labels': y[:, None],\n",
    "      'colors': color[:, None]\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "# Used to plot colored images    \n",
    "def plot_images(X, n_row=10, n_col=10, shape=(2,14,14), scale=False):\n",
    "    fig = plt.figure(figsize=(n_row, n_col))\n",
    "    grid = ImageGrid(fig, 111,  \n",
    "                     nrows_ncols=(n_row, n_col),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.05,  # pad between axes in inch.\n",
    "                     )\n",
    "    for ax in grid:\n",
    "        index = np.random.choice(np.arange(X.shape[0]))\n",
    "        img = X[index].reshape(shape)\n",
    "        if scale:\n",
    "            img = img - img.min()\n",
    "            img /= img.max()\n",
    "        img = np.vstack((img, np.zeros((1,shape[1],shape[2]))))\n",
    "        img = np.moveaxis(img, 0, -1)\n",
    "        ax.imshow(img)\n",
    "        ax.set_axis_off()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define, train, and evaluate the feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAItCAYAAAD16UpyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABFbklEQVR4nO3dZ7wlRbX38Z4HyWnIOecgGZV8EBCQK6IgQRBBUKIwCihJGUQBUYKSBRVUMipJcEBgSAoISM4ZJIchSRpmnhfe4a75zznVu7qrunud8/u+WutTe3dXTe+9T01XddWw8ePHFwAAAF33/9quAAAAQC/otAAAABfotAAAABfotAAAABfotAAAABc+ESocNmzYoHq0aPz48cMmxLTNjwltG6ztKgra5slQaNtgbVdR0DZPbNsm4E4LAABwgU4LAABwITg8BGDoeEDypVqpBQAMjDstAADABTotAADABX/DQ+Mkp9vVngMl/7GJ55Gy5zPXBZW8b+IV2qpEJg+beFEpc/+zcZ+Jl5Sy1yWfNXNdgAa5/+4CAIChgU4LAABwgU4LAABwoftzWhaRfHQblQgbY+LpS177qImXSF+VvP4o+Zck39TEZ0rZ59JXJ8Zkks9m4lWkbG3J9zHxelI2ukad2qBTwlYwsT7y7M1xki9sYm13580o+WsR770xZUXiHST5jyoeZ1nJvX8+kQZ3WgAAgAt0WgAAgAt0WgAAgAvtzGl5R/JpA689VvKDE9clATuP5Wwp06XQVzTxR1Km8y464QYTf1rKQl3eyzLUpYYPJI/ZCtW+Vq/v3NWq05g7JR8u+ZvNVAO9sPvZvlDyWvu97EtflTp0DsuqJr6j5L32N3EtKev8nJZ3JX9E8rEmXkbKdC2dt5LUaGL6B6cpif+wcacFAAC4QKcFAAC4QKcFAAC40NycFjuZo2y81tpY8k37fVWjtgyU7Sj5WMnvMrGuQ7Cq5P+MqVQq60u+uokXa7Ii9Uwt+WGSH25ine+i9Bp23dImPkvKBvMclj0DZbc3Vosa/mPiKaTsFsn78laljlRTGNaU/FeJjpuU3edJf8DvjThOExMcY485jYl1fytlJ2/+LvI8kbjTAgAAXKDTAgAAXBg2fvzAD38OGzYs5snQsPdMvJCUPS/5T028mZTVWPt+/PjxHz9UWKdt/5H8RRNr05Qdj3tfyp6WvOxYVqq2FQ9KHhoSGib5GSbWe/X6jxZhQtuSfh4j2OGh/aXs5zWOm+yaCbtkfdn/SuxqA/qU5WySvxpRh1xts3TI74DAa1OOgydr2+GSf9/El0jZbyXfwsQnSpk+ahuxBUDb3zU7SpJyhCTb5/FtE08X8T4dDtLx7LIxa6OJ71qplU18q5TVuJC2bRNwpwUAALhApwUAALhApwUAALiQ75HnDSV/yMQ6h0XtZ+I30lQnpSlrvDf0+Oz8NY6bTNmjbZaOydtnuN+WMkfd45kCZfc3VovebSb55wKv1ctg56l8Ucp0i4KYOS1NCM1h6aQVJf9+v6/6L13aIbTUw7Yl5/2D5F8veX2D7pP8z63UogY7F+VrUqY/JHZLmmOkLGIOSyd9qblTOfpTAgAAhjI6LQAAwAU6LQAAwIV067To09Qx22C/I7kd+/thxHFKpHqeXdfq2MXEMWurlP0TxTze3oln9S1t3CaS/7X3QzW9doSuQm2nDHRx7QgdDtcV4K1xkttJbaOlTHd0iBl2b+Lz+ITk8wVe24l1WvQzv0HESY+U/KDAa2v8sOT+runaP7qjyxwmfiXhebN9Hhc38RekTPeOuNrECX9IOvHbH/rMsU4LAAAYiui0AAAAF9LdNf2s5MdLvnfgvXpDK+GQUA6T3K/Cf80VKNM14jvsq5K3P9YWFvoSLy25bppuV9/W/8F08SnMdU0cGg4qClebkk9qdslDz5ufWnKs90rKG6R/BnQX8pRDQo142MRHt1aLbrkj7+G50wIAAFyg0wIAAFyg0wIAAFxI98hzDH38dQfJv5LlrNkeDbNPey0iZU9Kbqd9PCtlL0s+Z0Qdsj32trCJH5eypSS/18RXS1lobfkSTT/yrFstjDDxCQnPk+qa6RQwO9dDH3/WS/a6iXXnjTpyfR5D22BcLnlo5fs6krVNHxO1jdMP2p6ShyYyvST5PJLrc+9G7u+aNjn0NOzakl9f47ytPBZ8lOSTm/g76U7TuUeedaLS9tUPyyPPAADALTotAADABTotAADAhZSrW/duD8k/30otkvmJiR+Tsjcln8HEZ0uZ7mzeCWuZ+BEp0y7vtSauMYelaW+XlKecx5LDj9quQEbLRLz2qmy1yGReye3+ICNK3ms/lIdL2YtVK9S8b0l+WOC1cwTKOmk7yR39Jpb6cqCsxhyWXnCnBQAAuECnBQAAuECnBQAAuNDOOi0taeJ59pMl1zHbzU18UcLzduJZ/Uxyrx2ha3/sK/lxOU5aDI1rVhS0zZPc37WVJb9Vcjs95wcJz9vKNYtZlKaGVtp2iuTfNHHCdrJOCwAAcItOCwAAcIHhoUFiKLRtsLarKGibJ0OhbYO1XUXRYNtGSZ5ynwyjlbaFxvkYHgIAAKDTAgAAnKDTAgAAXAjOaQEAAOgK7rQAAAAX6LQAAAAX6LQAAAAXPhEq5Fl9P4ZC2wZru4qCtnkyFNo2WNtVFLTNE9ZpAQAAbtFpAQAALgSHhwAAyKahnZAxeHCnBQAAuECnBQAAuMDwUMNWM/GNJa/lTmlCM0r+nImnkrIrJf+ciWeRsjE16gQMBbOZ+AUpe7rJinTIm5LP0EotJjaN5IeZeISU6e2OY0y8T6oK9Y87LQAAwAU6LQAAwAU6LQAAwAXmtGR2k+SfaaUWKF6T/Dcm/mbJe79v4vukbJ7KNUpGnxq1HpJcP4+PmPhhKbuoaoW6SOcibS35lyVf18Qt/NfuXMm3ktw2Rz/anWPnsSwjZQ82WZGWHWDiLtwu+Lfkc0h+t4k3l7J3JD/LxLtL2dSR9SrRhX86AACAUnRaAACAC3RaAACAC8PGjx94U8ioHSMfkXyRijUqU6Ob1cRumD+T/LuB114guQ6zx0jVtl0kt3Nwdqx60Jpa33l2DRNfL2U1FtPJ9Xm08x22lbIpJbfXdzMpq7NOUCM7z35acp2Xsp+J/yVlO0s+SvJtTHz1xEWp2tYn+TUm3kvKdI7LSyZO+T/PJN81nWS1vYnPKlrRiZ2Qx5lYJzfeWv2wldu2juTXVa/DRMZJvqHkV/V+KHZ5BgAAbtFpAQAALtBpAQAALlSf0/JnyReTfCPJl4io1XSB83RwTst5Jt6i5LW59hNK1bb/SK7b8vTqScl/LvlJEcdqfU7L7028rJStWP2wbYyzHy35d0w8l5S9WOM82dpm90e5V8oWTnaWoFRtGyv57CYuW3vlPRNX/Y72p9J37SDJdUKOrv/RglbmtBws+aEmTviHoBPzdSyd01Rj8iZzWgAAgFt0WgAAgAvVh4emk/ztRDUqiqI42cT6DG4HhofOkzw0JLSG5PZ2fNlQ0rOSLxB4baq26dNq1g8kDz29+CPJtys57xgTzyxlrQ8P2duds0rZ69UPm+u27pkm1n93vdcaOmknH3m2H9AxJa/VD1Iiub5rMT9t9r2nSJmuoh6j0ndNhwN0OOiVipXRR9hPlly/i9ObWMa5WxlC0Qt8sYm/lO40nRse0nafLznDQwAAYCig0wIAAFyg0wIAAFz4ROV3ppzDouw8lt8P+KrGrCZ52VwU66Ya5523xnt7pfNm1PImvifiuMdLrnMr9GlVXW6+VWdKbsfka8xhacqbJo6Zl/JryY+Q/IBq1alnuOR2SXBdDnwFyR818aKJ6pPQRZLfYeIfS9lLxcDGpKhMSlXnsBRFUSxlYn1UVj/MV0hun+ffrUYdqvqK5Dq7JOE8lk7LPKuGOy0AAMAFOi0AAMAFOi0AAMCF6nNaUtIt5q1DGqvFx3QuyY0Jj/0PE+tcGaVDujnMI7kutx8zj2UGE18uZbrzuu7M3qodJNcJON34lvTs2xXft4fkoXV4stEFfn4ieWhb+50lf6/fV3WGLkNiLSP5fYHXXpmgLrX8QnJdtyVmYpWd7Fa2/L9u8VJjS40kdFJYzI9nF81n4hOl7H8kt/NYdGUVneuzpeQPm3jJ8mpxpwUAALhApwUAALhQfRn/lE6Q3K5DnbBbVXW5Y73bmctWkl8Y8d6qbdtQ8msl/yCiDvYxzQOlbH7Jyx61trIs43+LiXV/hMUlf7Pone5uvoKJj5y4qGvLb+vO229IHvPIc+W26Ss1t7vFPyJlH0o+ec9njdKF62ZXSp9Ryt6qcdwk37UnJLdf/k9J2dOSv2DismGl0PYB8th1I9dM67OB5NdkOWv1tk0juf7O3W3ih6XsOMntHIozpEyHbaeU3A7r3TxxEcv4AwAAt+i0AAAAF+i0AAAAF7rxMKfupf5AK7X4WBPL5xdF3JOAuYyq8d5pJbfzWE6Vspg5LElsLPllEe+ts1T/a5JXff64htVNrE8qhp4K3VXypfp9VWanSf5vyR8KvHeuxHVxos4cliwWktw+232KlK0UOE7ZZELdT6XO9gFV2f1KdPbFCMkzzWmp7AXJdZ2KTU2s8190G587TaxzWNT7kt/c76sGxJ0WAADgAp0WAADgAp0WAADgQjfWaRkneWgthhpSPauvQ612af59pSxyuK6yNtaO+KfkdlmMFRKep9LaEXqRdBESuxz8k1J2d9GIXNfMNn1qKdPl4W8z8Q1S1lejDsnaNjxQNqbyUWtp47u2hOR22l/K/3lmWROpA7JdM/ulWV3KGpq0WLltul7KM5LPYk8iZWdIXjaPpSLWaQEAAG7RaQEAAC7QaQEAAC60s05L2fhXwnksOXRhfZU27C/5ypLr8gytGqoXSbwruWx/1P1/pjFtV6AbxrZdAfRvrbYrUIOulzJ7K7WIxp0WAADgAp0WAADgQjuPPJ8h+faSZ+pKdWFL+VyGQtsGa7uKgrZ5MhTaNljbVRS0zRMeeQYAAG7RaQEAAC7QaQEAAC4E57QAAAB0BXdaAACAC3RaAACAC3RaAACAC8Fl/AfzM9+0zQ/WjvCHtvnEd82fodK2CbjTAgAAXKDTAgAAXKDTAgAAXKDTAgAAXKDTAgAAXAg+PdSUayU/1MSjG6wHwraTfGfJ+xqqB3o3heT3S76QicdJ2WmS756kRhjIASaeUso+kPx4E7+Vpzroz26SL2PiA6Xszcx1GaK40wIAAFyg0wIAAFyg0wIAAFwI7vLc1Op6oZNMshxenfNkWjnwVRPPJGXvSD59qpOKJlZFPE/yLSSfLMdJi0SrdI6WvK96fVJp4pq9IPkRkv8i8N6PJI+5vp1fpVNrFPFDU7VtT0quEwqvMvFBUna45Pa7N0rKNu+1Qv1gRVyhX6DZalTiZRPPWeM4ovPftRpYERcAALhFpwUAALhApwUAALjQiXVavHlV8gdMPJWUrSS5roUx0HGKYuIlAFDT2m1XoB0Jh867wY7Yp5zw1gBdj2rHiPfuIPlTJu7c+jm/l3xLE+vEKL2G9vpuI2UX1KlURddLrhOG7ISi06Xsn5I/aeIxUra45C+VVaxH9t/+HCn7t+TzJDpnrsmN/4s7LQAAwAU6LQAAwAU6LQAAwIVOzmk5tPwlrdK1WNY0sc53iekVjpT8fMm3LNp1l+S6TkunrFVSHppcFPKG5Dr2rGP0OlaNOLrqRNUfh5E165FAzBwWpVveHGziWWscN4mTJNe5KFXpHIwnJL8t0XlCfim5zmk5wcSXlxzLzvXQRZBukXyhIo1bA2Vlc1jswkF6HL3mdn7Mb6Wszge/H9xpAQAALtBpAQAALnRyGf9cTzJWXe7465L/TPLZ61TKmELy9yQP9TCbWMp5Wcl1uGh1E+vdzjqSLC2uw0ELm/jJykctimskP0Py3w381q4vv92JZfxT/Tgk/JHJdd2ON7E+xhx6MlitJnlohEBV+q49LvkCks9vYn3MVumHLmQryS8c+KWVr5n++P9Gcjs293rPR52UtvswyUcO/NZO/I7YD9l0UrZ09cOyjD8AAHCLTgsAAHCBTgsAAHChlUee+9o4aULXZTruZpKXPUHXtB9Irj3eTq+q/qbki5n4yYjjLCh5n+SfjThWIiMkP9LEk5e810650SH5l6tWqI6+Nk7aDW+ZOGJKQ7GH5DqfbBXJb4+oU0+el3x+yZ8qBhYzWUfpvgg56HwdrW+deSzWXyU/RPKRic6Ty7km1kmfiXGnBQAAuECnBQAAuECnBQAAuMCclg7RJQC+1kotBqYrWOvSJ51baMQaK7mdzDFXxHGOklz3bchgbcl1KF/X8/miiUeVHPsmE39GymLW90imr6R8ZMSx7LyAru8NUhTFgRXfd6Lkm0iu1zX5nJY1JL9a8nUijvWkiRcseW0D371Jfjf0R87+KP6xxnl0nwbdsmBKE79f4zy5PNbcqbjTAgAAXKDTAgAAXGhlGf+yg3ZtGX+lwyJVe36zSK6PmMYct4mlnM+TXHd57vQy/mpTE18S8T69+DtLrmN8Ab1eM13hW2/vf6r3UxbLSH63ic+Vsm0jjquyLeMfokNAdngo4Y9K1bbdLLkO21Q1s+T6O6Kjn7oxuZXluxbD/iPps9o/kVwfCw5I9nnUL6P9x54z4jg6hne+5FNJHthDoxPL+NttUR6Rspj9PwTL+AMAALfotAAAABfotAAAABdaeeTZO11i+2ITf7EIs//gOrZ8ZeUaIVrMPJaQt8pfUtcukp8q+WaST2Pin0rZ3JLb+Q6huQ6tiZmL0sSy7jXMK/nUkr8bcSy7C8WDUnaD5J28rhNML7nOY7Ei5rBko2sIbGhine9Sx1YJj9UEneuXEXdaAACAC3RaAACAC3RaAACAC51Yp2W05OvmOGmR73n2B0ys48e66vsfTKyrMcc85q+aeFZ/Gsl1OkeNx/GDWl87YlUT6wI0Nbr9Va+ZzkvRneDtyuLHSFnVpeJjtbJ2hJ4l04JPVdu2pOR3Sx76/ujH7A0T6zL+B/VaoX40/l3Ts9i5EftI2XE1TpPr82jXV9F9TkLukXyF6lXoxDotdl2Zd6RsB8l/3/thWacFAAC4RacFAAC4QKcFAAC40MqclrY0MfZ3kuS7Sv4VE9fZyVx1Ylwzk9bntPzVxBtIWaJ9NQbrNSsK5rR4kv27tqbk10n+polnSnfaoXDNiqIjbdP1an4rue7XFsCcFgAA4BadFgAA4ALL+Ce2e0kOhzZquwLoSabhICS0QEn50o3UAk16KO3huNMCAABcoNMCAABcoNMCAABcCD7yDAAA0BXcaQEAAC7QaQEAAC4EH3nuxOp6CXVu5cCEhkLbBmu7ioK2eTIU2jZY21UUtM0TVsQFAABu0WkBAAAu0GkBAAAu0GkBAAAu0GkBAAAusGEiMJ/k10i+WFMVQTarSH5KSTkQaUfJTw+8djrJ301cl8GMOy0AAMAFOi0AAMAFOi0AAMCF4IaJg3l1vai2HSX5NySf3sQ6S+hFyZ8w8U0l571a8lEDvzTXqogzmfglKXtf8gdNvKKUTVajDtlX6fxAcu3KH2riw9Kdto2VLJ+QfIHAa/8s+fOS7xl4bydW6VzOxHeWvDbiv29ttG2c5Ln+t5n7u3aG5NtJnmuSZa5rNtbEunTrLpLbaVNzSNmXatSh17YtI/m/apxzW8kvqHGsEFbEBQAAbtFpAQAALtBpAQAALuRbp+VEyXeteJz7JF+u31fldZbkX5V81qYq0rzHTTyllOk4u/VRhroktWHEa3czccI5LblsbeKTpUzHzkebeBMpu7TkPKE5LZ1wdqBMGwtUcLSJfy5lL0s+3MQ3ZqlN2AYJj3WO5PZP5BQJz9Mf7rQAAAAX6LQAAAAX6LQAAAAX8s1p2aMk71UXJkfcJflcks9mYh3IdG6m8pd8bKpstchghojX6sSQjjlXcvvxjLl+fykp/37EsVqh892WDrz2ipwVSW+SxSqceqbtCiRW9TvxetJa9Oa4kjzkaMm/E3jtUpI/EHGeXnCnBQAAuECnBQAAuJBveKgO3be7a+aV/BET65Lws0QcdyvJL4x4bwecaeLODyX8I+K1HbsOPygpXyfTeX+W6bjJXBsomz5Q5sBg2U/lFMkPaKUW7TjQxDO3VotqbpZcl7sILX+RGndaAACAC3RaAACAC3RaAACAC92c03KriX/fWi0G9rzkdrx8bil7MeK4J0i+pOQ/jjhWA+aXfGMT6/ScznnWxNp1n0xyu4z/XnmqE2Ok5FrdGPbx6H9L2W01jtsIfRRdn+++wcTvZK4LhryYnWt2kfzUxHVJbfOI1+oKIb+QfL+adeFOCwAAcIFOCwAAcIFOCwAAcGHY+PEDrwAwbNiwdpYHsEv36/oK/6l+2PHjx3+8GnZU21aW/PbqdYiiWxgEJi9UblsNYyXPNUFqQtuytUvX1tGuvF2EIOG+61Wvma6JcFDgtXNKrmPpoebU+R9Nts/joiZ+uOS1dr2nGr8bqo3vml7zXP/bzP1dGy75K5LbaUlvJTxvE9fsMMmfkvxvJr5Syhavcd42Po/naB1MvEXJe4+T/HuB19q2TcCdFgAA4AKdFgAA4EI3hodGS27XDN4/3Wkq30Z7TnJ9rDmXjg0P6c6k20t+aY6TFgwPqWMk31tyez9VVwz4leT2qeDNpOySXivUj2Sfx3kkD20TvIbkMVs1RGjjdryOSOuIdSrZv2tCh5g9Dw/FuEPylWocq2ttU/rzqkI/qQwPAQAAt+i0AAAAF+i0AAAAF9qZ07K85DrAV2dd8oDKY3+6Xv3fJZ+3RqVCOjCnZW0T6y4CaxfNyD7Ofq7k+sxex+a01HGw5N83sa4uUEeytsXsed/Qf8HauG56kkkG+lOdp+U5LXYpfJ2rVUev10y/AzqvRh/RtnNRnpYynfpoyxeTsicGqlAPcn0e9dpYWt9RJg5tX1AUE++gUhRFsWDgtcxpAQAAbtFpAQAALtBpAQAALuRaeT1M57As1UoteqeDlZtKbuee7CllF0tuB0l1rsxtkuuCHC241sQ6peZTkn/DxF+QsuUkf7VOpdAzHTv/keSd+1/LsSXldlLB7Dkr0i2dW3wjkcskX7+VWvyfsrVhTpP8cRPr5Au9ZmeauM4clqaEppMtJPm3Au+7X/JtKtfovzr3mwUAANAfOi0AAMAFOi0AAMCF5tZpedfEOqdF9wzJpJH1FY6QfC7Jv2biC6RsD8kjJn7katsIEx8tZT+V3E7B0fUM6mh67YimNPF51KV+lpH8wRwnLbq/H0odbbRN5wnk+t9m2981uzZIygmXfB7r0S3AZoh47wM1zss6LQAAwC06LQAAwIXmhofuMfEBUqbPvWXCLUKf2r5lnctQuGZFQds84bvmz1Bp2wTcaQEAAC7QaQEAAC7QaQEAAC4E57QAAAB0BXdaAACAC3RaAACAC3RaAACAC8GVkgfzM9+0zQ/WjvCHtvnEd82fodK2CbjTAgAAXKDTAgAAXKDTAgAAXKDTAgAAXKDTAgAAXAg+PZTNzCXlY0y8pZTNIPmvatcm3jWSr2PimLnbf5N8o2rVac3GktvduvXf4QTJRySvDRL7UPLJW6kF4MTpku8o+WMmXjxzXQYx7rQAAAAX6LQAAAAX6LQAAAAXmpvTspWJz4l4312S3yd5G3NaPlvjvSNM/POa9WiCXY/wDin7pOR7m/g4KVun6BQ7HecyKdOe/LjAcRaW/KnKNWrfXJJf2UotSkxv4rci3jel5HdLvkS16jRGf3OuNvEka4Z2zHkmnl7K/iH5uibeXsqeTVajdD4y8StSNqfkXzTx61I2U7Iadc6Sku8k+ZMmPrGH43GnBQAAuECnBQAAuECnBQAAuDBs/PiBFxZJumPk2SbeWspWlHxVE+uz7zV0YjfMZ0w8XMp0vDdCtrb9zMTflTKt739MPFbKdNx9st6rUGXn2dUlv0LyaQLvjZnTomLWMmnj83is5N8x8TtSNm2N83Tiu2a9L/nUkkdc5EbadqnkG0puZyPqfB1dYCdCll2e7e9C6ItXFEVxsIl/nKwG6a5Zn+SHmHjdonf6+1hjdmkb3zVddmv3iPeeLfmuJn5bytjlGQAAuEWnBQAAuECnBQAAuNDcOi06j8XStVg0H0zsYhhfba0WvdtvgDjW8XUrEue3kutQ+v+YeJSU3Sq5TrmyFompVAu0LTo1wg7D61ZYahbJX61Uo4R0D7DQ+knXSh4zUakpdq8avVBTSH6ViXWNj5eS1SiNh008XMrGSG7neujcnAUl/3flGqWzdtsVaIb+SX5N8ibvfnCnBQAAuECnBQAAuNDc8FDI0pLf30ot8rg+UHZ+Y7VoxkmBsoSPL/bi05LPILl9ervOMv4LSv50uFqNmN3EWh9dPdwu1a+Pa+ujiZ0YzbQN+n3Ja98w8YwZ6pLaaSbWPRV06Gs9E28jZb9IVqM0VjDxC1L2kOSXmzhm/YCm6DYy1oKSPym5bfuYBHXJ7EITLyZlfQ3WQ3GnBQAAuECnBQAAuECnBQAAuNDcMv5VHzH8keQjq1ehkeWOp5Jc1yU+0sQHF8m0smz6bJLbMdsjpKxGW1MsLR6zsrn3ZfzvNvFyUraZ5LatOr1A/x3uiahDsradLPmcJv6elH1Jcvtd02fgd6pco3zfNfu4r/7j67PrnzKxzkys8Th3lmX8LV17QH8fbVsSPpae7Zrda+JZpUx/H58y8cLJapCsbXNK/pyJL5Ay3bHArmhxWNUK9INl/AEAgFt0WgAAgAt0WgAAgAvNzWm5ycQ3S9lRkp9nYl0mWRfV2LT3KmQb17SLgtwkZc9JPn+ys04kWds2lnxPE2+kJ5Xcjj5OVrkGk8g+zh5hVcn1oxzT7FTXbHXJbzCxTrF6R3L7cT1cyq4qqkv2efyK5L828TFS9kPJ7ZyChHsOtDJ/TC/OXiaeLt1psn/XdD143SPDTj7L8BtSFInbNr2JdRGkkJ0lP6N6Fdr4POoyQna6ju44UQdzWgAAgFt0WgAAgAvNDQ9VpTXQPKLblew22rSSv2XiB6VMtyjIpHLbHpN8gcBr9UZdaHjo11L2Lcm3kPzCYkBtDw+tY+KynZDbeORZnwyd2sR/kbLjJNfR1lRaGUJ5QvKF8pymlbbpRZ7bxLo0fg3Zv2vaDv39trtbLyFlv6x+2mzX7CMTXydluvXC3iY+WspqbKhTtW19ko+OOOcjktvqp/zaMTwEAADcotMCAABcoNMCAABcqDGSJnT88TeS22Xcry051l9NrCN0+shcE/S50Tckt3WcueS1Oh/G0tG7lyTX58yq2F7y0BwWdaDkP5XcTpD4hpTpsumXSx6Y09I0rdoGgdcukrMiPZpF8g9MvKaUrZ+5Lo26UvLQhfJG26LPqiecx5Ld7CbWD6Syv59vZqhLTmeXlP/CxDqn5STJd69fnTI/kfxxyW1zdIcC/d1r8u4Hd1oAAIALdFoAAIALdFoAAIAL6dZp0Xkfz0qucz16dZrku1Q8TlHjWf2VJNdt4seY+BwpO1dyu97xPVKm6xAcUlqzj/XctuUlv13yEZKf0HsdJqLbK4yR/PreD1Vl7YhXJJ+x99NN0pO3S0vErMNSJtfaEZ8xsW4hf0Sqk5RoZC2TsjU/Mmmkbfr7uaXkf89y1jzrtPzWxDtK2XaSn2jimC9tiWzXbD0Tj6pxHJ0TqutnBaRqm+6YY/906Q4Fm0uuy5OlwjotAADALTotAADABTotAADAhe7vPZRQK3uGNGQotC3XnBZd+meVXk9S01C4ZkXBnJZKWm5b0nYtauKHpWyE5DX2Fwrhu+YTc1oAAIBbdFoAAIAL6ZbxBzpEl53GIDSY/8s1mNr2qIkHU7vQCj5CAADABTotAADABTotAADAheAjzwAAAF3BnRYAAOACnRYAAOACnRYAAOBCcJ2WwbwkMG3zI8vS4h0wFK5ZUdA2T/iu+TNU2jYBd1oAAIALdFoAAIALLOOPnh0v+e6Sf9bE12WuCwBg6OFOCwAAcIFOCwAAcCG4Iu5gnoncibYdJrluTbxb74dqom1jJd9A8mtznLTgiQaPOte2vpJ8ZO+H6kLb9jXx81J2Vo3jtv1d+8jEq0rZHTWO28Q1e1/y6SX/IMdJi258HnPh6SEAAOAWnRYAAOACnRYAAOBCukeedcJDDB21+quJN6lx3K47sKQ8Yk5LE+6UPNccFqAn+gHsi3jvoQnr0YJvmPiC1mpR32qS2wkZt0rZNJLnmiMS4xwT3yBlofrpfMA7JX+5aoUSWtzEF0vZUjWOq12F2E4Id1oAAIALdFoAAIALdFoAAIAL6ea01DnSipL/08RLS9n9Nc7TBaHFBtZqrBY9+7mJH2mtFqjsy5JfGHjtPZIvn7guKdh5LH1SpvNURmatSauma7sCFe0h+S8lDy0ycqbk29SvTm1bmniyiPd9KPkLksccKxf7p7bOGjn31a2I4E4LAABwgU4LAABwgU4LAABwId2cljp0gNau2+J9DsuCktt5Au9J2d/zVqWKESbetK1KDMTOb7iu5LWHZKrDJDtjtGAzyf9k4uekTBdYeMjEU0jZ45IvIHkTA++htVhy/tvbyRUduMb6v8t5THxEkxWp4CATO18eZ5J9nfQr0qvRkl8j+dOSz1/xPDFCS62tE3Ec3XNpCcl1jZpY3GkBAAAu0GkBAAAutDM8pLehR0u+q4m1hnW2C2jDY4GyNRqrRWX2zvhdrdViAOuaeGTJa1M9Dqvv02c0mxhKOE3ynSRfxMRPRBxX1x1fWHL9N3zWxPNGnCeGnrPPxCOlTPMQfa0OH65bdMqlktuPmY4yt2245DFDQvYjqH8mumBryfUrUpUOmXyU6Lgh10e89sGI185TUl53+xfutAAAABfotAAAABfotAAAABeGjR8/8MLJw4YNC62qXN3rks8geeism0g+qvfTjh8//uOh4GxtW1NyfRT3GRMvmO60udpmpxDpE6//ltxuM6/btKuYyVQT2pbtmtVRY05L5Ws2TvKZJH+j9zpE0YtmJyDIf3+yfdf6TKzzUPqK3tWYe9TI74jQOQ52e43vJzxPiu9azHwMfWo+9N4LJNf5JSGprpnWL9VT/6tIfkvEeaq2rc700Jsl/0zgtfq49E0R57Ftm4A7LQAAwAU6LQAAwAU6LQAAwIXm1mmxA2gvS5mOyVsbSv4XybuxEcH/KVtOfsEmKpHHFyX/tuSLm/g4KVshdWXaMrLtCvQj1xyW+SR/SvLNMp03xM5j6Yt4XweW4o9xbEl5ynksqYUmVZTNQwm9d58KdalrT8n/luk8uhWDzhfMoc6fzrklt9sO6DJSMXNYesGdFgAA4AKdFgAA4EJzgytVzxTxSHNrLgqU6ZiKM7OY+NWS185sYn2Eb2/JdannJm6HJpFrt+gY50h+vuR27KBsGf85TfwrKdtY8qUlj1nbuyodLxht4pghn5Elecfo9yVml92mrVb+ko9dKLk+Qty1NQ1elHz5RMe9U/JPSp5rV4xUdBdqa7fM5+ZOCwAAcIFOCwAAcIFOCwAAcKFrDwxP6hXJ32qlFhPTCRtfCLz2spwVyc8+TVu2hPVrJn5Pyk6U3M0cljKHtnDObSXfUfJbKx5Xn2HftOJxcuqr+FqdizSybkXSuz9QVrYtRpv+EfHamKXj75S8jd8M3TpgdclfMvEVUrZd4LjXSq5zWJ4vqVfTdLUDtWATlfhf3GkBAAAu0GkBAAAu0GkBAAAuDBs/fuAn45Nuu/6uifeQsvklP8jEt0lZzKIAItmW8n+UfDMT67oyn698lijJ2tZBE9rWiXZpDWosDz8UrllRJG5b1SMlXMY/V9vGmXhyKdP5ZLmk+K7pWia3B16rl2U/Ex9TtQL9yHXN9jfxFlKma9IcmeqkIlfb7LYsoflWRZFvcqxt2wTcaQEAAC7QaQEAAC7QaQEAAC40N6fF7ltyt5SNkXw9E9+VrAbMIXCq9TktI02s630wp6VftM2n1r9rmQyFa1YUadu2oIkflbLpJX+3yIM5LQAAwC06LQAAwIXmhoc6gFuEPnHL2h/a5hPfNX+GStsm4E4LAABwgU4LAABwgU4LAABwITinBQAAoCu40wIAAFyg0wIAAFyg0wIAAFwI7ig9mJ/5pm1+sHaEP7TNJ75r/gyVtk3AnRYAAOACnRYAAOACnRYAAOACnRYAAOACnRYAAOBC8Omhpiwq+UMmPl3KdslclybtI/nRrdRiaBpn4mOl7LOSf9PEt+WpTnPWkvxdE3tv3MqS72HiHaVskmcSAAxkf8l/IvkzJl5Pyh5LXBfutAAAABfotAAAABfotAAAABeCuzznWl1P5xDsJfm4YmA6XnZ9xHm7tnKgtrNOD7KJtm0p+XclX8PEHyU8b4pVOr8m+RkVj7OV5BdWPE5RtPR5vEbyVUw8Q7rTNNK2L0uuF2OMid+Qskcl36D30zbRtpGSbyL51SbW+QZ1JFkRV3/IPqx4nFGSf77icYru/farpyVfQ/JnioHlatt+Jj6ixnH+LPlXIt7LirgAAMAtOi0AAMAFOi0AAMCFxua0hIY1tecUmtPyjuTDI+rQhXFNuxTGm1Km64PEyNW2U018hpT9Q/JHTLxYqgoUeXaetcuVvCdli0v+OxPr1IiZa9Qh2+fxPBPrAPITkl9gYm1cjYHsZG17SfLZKx7ne5IfJvmUvR8qVdt0isalJv5Ayn4puZ2jNYuURTRlEkm+a1NI/m6/r/qvPslvMPEfpexzks8muX6RjTZ++/UkdnLGfFJ2k+Tzx5wnUdtmlPxVE98rZStEHPc6yZeVXD+/FnNaAACAW3RaAACAC3RaAACAC9nmtDwr+RwmvlrK9pZ8axMfLGXvS36n5GsG6tTGuOZwyV8zccoeY6622fUDysZZ5zLxnFL2rxp1yDGnZXkTnyxlnw68T9dPuLlGHZJdM51ctJqJp5ay0PyCtyWfrnKN0rUt1WJGepydJP9t74eq2rY9JT8+kOvaVSF3Sq5zZZ6LOFaS79ofJN/GxL+Wsm9FHHcJye+XfLKB39rEb78eVH8v7Vorofku0edN1LaxgTL9+ui0pRg69eifJtat0ZjTAgAA3KLTAgAAXPhEqgO9Irk+PmWHizYqOdahJj5ayi6RXG8ndY2uFn5aK7Xo3YKSrxPx3s1NrNepbStKflu/r+rfaBPXGQ7KJjT2FhoOUr+RXG+3p9yboVdvSX6XiZcvwu4IlEUMB6WiI1I6BGSHh/T385uSb2fiT0qZDs03/j/T1QNlMcNB6qGI8/69xnki2NNcIGW69P6WgbI2bF5SvpSJHxnwVfFWlTx26gB3WgAAgAt0WgAAgAt0WgAAgAuVH3neQXJ9kk0FnkaLcq3ka0ecp4nH3vQJU912IFcvMVfb7NirLj2t7CPP+tTjejXqkOORZ7uFwrQR77td8p0lvzviWMmu2VmSb1vxOF+Q/B7Jn+z9UMnaNrnkr5t4GinTHyE7iUT3WxhTuUaV23an5MtFnPNKye0lP1PKFpX88YjzJPmu6dynP5t4i8pHnZR+Pu1kno0nLkr1eTxf8s+YuGxJCHvSOo84T3Lcim3Ty6TzL/UJ81T0N9JuF7CulPHIMwAAcItOCwAAcIFOCwAAcKHyOi06fKzL/K5S9cBiM8l1mX49b9sellyX6vbGzmN5QMp07Nx+mFKO2eYwQ8Rr7Vj1qVKmawzosiLDI85T2TaSV53TcqnkOmHn9IrHreNDye3WAjdKmS6EcpGJxySqTw0rJDyWXfpcd1+ImcOSxKwl5bkWp1pa8pSLiQzgK4GysskkuttG27S+Z2Q6j24roZcttG1Kf7jTAgAAXKDTAgAAXKj8yLM+LqXDNPqkYoiuqL1dv6/q3/ckPzbw2lyPBdvHrPVudlO9wjZ2sNaxRfuY89ZFOlUew5xd8qMk36FiXaaSXB9pV408gv8dyS82ccxYwaaS6/3sl3s/VLbP40Um1vpeJfkGJk74RWzju6a7ptudm+s84qwqPfK8uOQ6jpxqvQt9xFnHGVre5XmSc0qea8i8att0V+dUe/roI/g6Wn245D8MHItHngEAgFt0WgAAgAt0WgAAgAuVh7G2kvwcyXVuR4j2nEKPMesy6qE5LE3Z18SXtVaL5n1S8gNbqUX/5pL8a5KHeuu6ZbvOYwm5POK1yeiX4F0T674SIbqOwWzVqpOULtVv57HsLmWnSH6Iia+Wsjr7SrTgMcnfN3Hjjzir50vKlzXxvRHH1YmTaoOS8obpEv/6N7Lr9pPcLtehHQX9qbC/mTqpZkXJdWpSLO60AAAAF+i0AAAAF+i0AAAAFyqv06L+Jvk6EZXQnpMdo9XxMF2yOkauZ/VtW3VYfalUJynRxjoER0q+f6bzVFk7YjHJdemIqmsm6PbtW0geM16b7ZrZPQpukrIfSG4nIul62jVqlKxt00n+ZsXj6ASDCyoep2jmu6bzxe6SPNf/Niut06K+JflJJv6FlE0p+W4mfl/KZpJcywOauGZNrcsyyXkrtu13kn+1Rh22NPGfahxHsU4LAABwi04LAABwgU4LAABwIdmcFg/amPfRlDbadrTk+2Q6T5Jx9g7i8+hTE23T/Vs2llz31koly3dtIxP/peS1doLgjclqkO2a2bkculXXM6lOUmKofNcm4E4LAABwgU4LAABwgeGhQWIotG2wtqsoaJsnQ6Ftg7VdRUHbPGF4CAAAuEWnBQAAuECnBQAAuBCc0wIAANAV3GkBAAAu0GkBAAAufCJUOJgfn6JtfvAYpj+0zSe+a/4MlbZNwJ0WAADgAp0WAADgQnB4CIjxWRNf01otAACDFXdaAACAC3RaAACACwwPNW0tE9/QWi0qmVzy9yWfoamKoGfXSr5uK7UA+ves5HObeCop+yBzXWo7TPIftFKL7ple8q9L/pKJzy8/HHdaAACAC3RaAACAC3RaAACAC8ENE7Otrrea5CMkv8PEp0vZ4pLrvJDALJ1OrBw4zsQJu4xNtO0dyafNcZJ+5F6ls0/yQ0rKrUmWa4zQxDUrO+ihJh6Z8rwtfNd+Ivl9Jp5Fyo6vcZ5UbdM31vksWW9Jrm0PzQ3J/V3bUPLLJZ/RxHNK2aM1zpvs87i15GcFXvuR5HYS4IFSVuMD2Ym/a8eYeC8p0w/2lZL/0cTy954VcQEAgFt0WgAAgAt0WgAAgAvNzWkZm+xIE1tZ8rsGfmkrY3/zSv4dE++T7jS52vacideUssdTnaREjnH2XBc/Zl5CF+a0WKnmVBRFM23bRPKvBl67uuRXS75zxHlTtU2nPExW8ThTSv4fyWeU/O3AsXLPaRknuc5DyrW0SbLPo140SxdFelHyRUy8qpQ9J/l8vVepkb9r+0p+pORHm1gv6pvVT8ucFgAA4BadFgAA4AKdFgAA4EK+vYd0sQA7WHlEtrN2zx8k366VWvRsNskvMXFTc1hyGBko0/14Rgdeq8PW11WpDJL4S0lu7SR5zByWVBbOdNy7S8pDc1iasL6JdcKFu+15TpL8eyZ+N+I4s0uumzDppKv1Io6dyqIm1jksLe5ayJ0WAADgAp0WAADgQr6bPFNLbu8DLi1l00m+kol3l7LQPeAuWltyvQ3YMU9JPk3Eez9vYr1Melu4S73l0SXlI03cJ2UMD3XXsiY+Vsp2abIi/0uXrFcxT9PaIZcppCy0snwb7LYYR5W89gATf1fKLpFch/wa8e1Ex3lJ8s0kvzTReWJ8X/IfmrjF4SDVpb8dAAAAA6LTAgAAXKDTAgAAXMi3jL+usW0HK2X76UmeyVvRxDrOVmNsrZVl/HXd6kzdxFRtq1NdOyavS5IvJflwyf8ROG6KpcVHSn5Ify+qoM7S9yzjX06f9Pymif8qZedJ/ryJdT6JLvmvj/q/HKhT1baF5qwUxcTT906VspskX87EOu+s6nYARZFnGX/bbt1O4e+S32/iLQJlRTHpNXstUIfKn8fPSD5t4LWvSB7YUmYSOq/zDckDFzXbFgW2PTNImU6ksl+Y9aXs3so1Yhl/AADgF50WAADgAp0WAADgQr45LamMlbzrc1q+Lvn8kh+W5aytzGnZVfJbTPwvKdNpTDHLqOcYZ+8LlOmaGFYX530EzxHx2jbaNr3kr0uuw+z/NPFqUqafVftZ1tXXR0l+seSheSFVr5uec8Ne39gPuwr881LW5Tkt6jbJPx1xnJh29nzNbpV85YiTKP1C2WX+j5Oy/SX/QHJd98xoZa6msosi3Sll20h+Qe+HZU4LAABwi04LAABwId3ivGX3eTu0DHBWeptPn/UdRPSWu+0BHyxlt2euS6zRJi67n5py2KRph0qe6lHvVHQTdP231p8NOySkX62HJf+GiU+TMt0dpM6QSq/qDAepNUz8TMLj5mCv6a+lbHPJbbtukDJ9bxb6aK9aVfI7Aq/dW/JjTKx/J1SNx4RbYev7gpQtkPZU3GkBAAAu0GkBAAAu0GkBAAAupJtpossdqx+YONNjv62xSxoHHk3zYA3J7Q4Luiu7Ptb8oYn1keYz61Qqg75Amc4DQT5fzHjs3wwQDwZ2ztiWrdWiN3bO2NpSNqPkdh7LzVL2zaIBS5aUa6V0jouly3XYrWyOkrIVJG9iEqAut697V9j63ydlJ0tuL87dUvbzyHqV4E4LAABwgU4LAABwgU4LAABwId8y/o9JHnpWW8cJ7V7ruuTvEZVrlG+542dNfJCUNTSZoxNLOWeSYmnxPsmbWqo/pI1rFjqJty0K2tKFtj1lYp2a8EiN4+ZYxn8OEz8nZcdKvm+qk4ouXLNcKrftjJJyu4XBcCm7SXI74VHnxtTAMv4AAMAtOi0AAMAFOi0AAMCFfDsCLSL5vCb+nZTpw/t2oLPGHJbGzFv+ErSrL1C2blOV6ADP+yjh/9ifHJ0+2DUvmriJPZ7Qox3arkA13GkBAAAu0GkBAAAu5HvkuYN47M2nHI9hdsFQuGZFQds84bvmz1Bp2wTcaQEAAC7QaQEAAC7QaQEAAC4E57QAAAB0BXdaAACAC3RaAACAC3RaAACAC8Fl/AfzM9+0zQ/WjvCHtvnEd82fodK2CbjTAgAAXKDTAgAAXKDTAgAAXKDTAgAAXKDTAgAAXAg+PVTLWMntHOAbpewEyS9IXx1gKPqn5NtL/kBTFWnCkpLfb2L+e+aCffTlNCn7VpMVQWfxVQYAAC7QaQEAAC7QaQEAAC4Ed3nOtrreFpJ/QfKtTXyGlO1S/bSdWDnwKBPvI2WTVT9sJ9qWSZJVOvWdx5r4u5WPWksT12xcxGvPlfyrNc7byudRG7u2iXUeXQ1NtG0myZ+WfBoTj5Cy42ucN/eKuDp9cbeI9z4v+bwR7812zS428cZStqrkdyU760Ra+a6tK/nfIt6rc1a37vdVRVGwIi4AAHCMTgsAAHCBTgsAAHChnTktMT6S3Pu8j2tNvJqUTVX9sK207UPJrzHxp6TsQsnfk/zbA58myTj7SpLfFnitTgrYu/JZg3Jdsz1N/MuI9+mUkDqLODXyedQK6mcq0ypUqdo2QvKj7Tmk7HDJzzfxnVL2eclvl/zVQJ1yzGl5yMSL1jiOTpvYMOK92T6PHwTK9JbAKBNvkqwG7fz269/lW02sc3umlvxZyQN/05nTAgAA3KLTAgAAXKDTAgAAXMi391Aq7c+qSWsdE+/QViUizG1iHYtcX/JrioHphImmu8t3SG4/Vzqm+mvJbd2nlbJ361QqD7sWhq7vcbnkdouwmDVdOmG05Ae0UYneLS/5zyU/zMQja5znCslXljw0pyUFXY7EzmPR+TajJF/OxP+SMv336oSzTVxnYaOuu07yFyXX+ZnWbyWvuWYSd1oAAIALdFoAAIAL3RweWqHtCiS0e6Dsd43VorqLTLywlD0puV1b/EEp2zlRfVLRx2OtnSS3zw2/KWWTp6lOLpeUlOtOEtbSkt9fsy5J2KG81aVszSYrEq9sJPGkiGPtGij7pORNX7dlJX/BxDocpO4OlC0i+VU91yijHUw8mIeHhkse+lCdLbkOHc1ZryrcaQEAAC7QaQEAAC7QaQEAAC50c07LLSaevrVapKFLwh/ZSi2qs/NYzpQyXZN7LhPvKWW/SVajNH5k4jmkTB/ns89w1thGoin2kdeYpc51zkUn5rCo0FYXP5LczlvSdfBb8LDkx0p+p4nnlrJlJLePtS8kZc/EVas2ras6q+JxX5ZcL+8pFY+bjc7j00lhnv1Q8j9Jbpf11wlXief6cKcFAAC4QKcFAAC4QKcFAAC4MGz8+IHXyc+2zfWUkr8jud22u+zBfj3W+wO/tJEtvHeR/GTJM3UTW9me/ATJ7ZrwI9KdZkLbGmuXsnN3dGJCjeuZ6prdKfly/b2oBzNLPqbicYoi4+fRbqPwVsT7jpJ8/+pVaOK7pvOLppA819SqKt+1EZIfLXnVuupcnUdrHLeR30fdKkS/iHafDL2gNSRr2+yS2zmMnyt5r92foexvdgTbtgm40wIAAFyg0wIAAFxo7pFnu9XorVL2WcmfN/FIKTtEcr0XuW9ctZLrk/z2NiqRie5wrFsUDNYu8A4mjhmSaEjMcJDea7X3knUT7+mqVac550m+jeT2Frxu21BjeKgJujuE3vO3qws8XwxOf5P87VZqMYjNIrl+kOxUh42l7KOiNYP1zwwAABhk6LQAAAAX6LQAAAAX0s1pWVnyKyS342c6QHt14Lg6b2KSB6A6ZkvJdT91z16VXMdEB6sDTdzXViUGNkby4YHXbiv54ibWlbr3kPzE3quUj10eYTMp02dk7zOxzqProDkDZfpDfY+JdUqgLn+f2zUl5Y+YeDUp+4bkRwSOs1PPNWrJSpKP7fdV3aFLVui+CKc3VZE43GkBAAAu0GkBAAAu0GkBAAAupFvG/ynJ55Hcrp+i6ys0tNBAtqWcnzOxDkw31C3M1rbLTHyulP0h2VmCGl/G/0rJ7Vj1rOlOk+uazWTi1yPep0sv6PQx/UqHvraNLJs+n+T6G/QrE++a7rRNtE2nQywpuZ0yeLCU6c9rjBTfNb0M80a89wMT7y1lvyqqa2WbE72Idnn7TYpkKrdthOS65tkvTbyXlOmPRcJtCSyW8QcAAG7RaQEAAC7QaQEAAC6kW6dlgWRH8udiE9/SWi3S2Fxyu85MQ3NYGqd7Kq0vuW7Z3nEx81isyZLWogHPSD6I/gt2s+QPBl57Sc6KVDCU/xQEfbXtCojjJNcfgKNMrB/AZZLXpmeD6GsOAAAGMzotAADAhXSPPDvQymNvDanctrkkHy35EtXrlErjjzw3hM+jT0OhbYO1XUVB2zzhkWcAAOAWnRYAAOACnRYAAOBCcE4LAABAV3CnBQAAuECnBQAAuECnBQAAuBBcxn8wP/NN2/xg7Qh/aJtPfNf8GSptm4A7LQAAwAU6LQAAwAU6LQAAwAU6LQAAwAU6LQAAwIXg00MABrepTPymlE3RZEUq2FTyz0k+s4mvlLIzktemB8tLvqbkJ0Yca10TX1utOk2xf2TOlrKNJJ/XxPp57AL9Tpxi4h2k7BLJv23iZ1JVaAjiTgsAAHCBTgsAAHCBTgsAAHAhuMvzYF5dr07bdpd8axMvImWXS26HtT9VtQL9SNW2YyTf28S3Stk+kv+96klLVFmlc3/Jvy25nf/wbkRd3pP8uYj3qlwrWb5jYv08HiX5diY+Vcp2q1GHXG0ba+KXpexkye1SmgdLmU4vuT+iDsna9oTkC1Q8znqS15jjkmJF3Fkkf8nEK0jZPZJ/ZOLJqlagH6mu2YOSf8fEH0jZ5JLbvwUp7xY0sSLuSZL3SX69iXdNeF5WxAUAAG7RaQEAAC7QaQEAAC40NqdlexMfKGWLBt73e8l3rFGHqmN/l0m+muQ6hturNyTX8V1dxiGkiXHNhSR/TPKLTPzlhOetMs4+k+RHSr6tiaeSMh1EDZ30ecnnK6nXRMfNdM3GBcruknx9E7+aqgJF93aeHSt5nQWqWmnbMpLbH4uE//VMMadF533NbeLXpGyE5HZOnU7xqbO2SRc+j/Z76WFOy0eBskclt+vXzCVl+vsagzktAADALTotAADABTotAADAhWRzWnTI9W7J7YGukzJdX8E6T/KpJddn40Oqjv09JfmKkus4bVU612d1yf8n8N4ujNm+MkBcFEWxZI3jphhnT0XnRvxR8q0ijtXEnJaZpWxMqpOU6MLn0Y7J67o9P6tx3EbapvsQxSyao5PsXu/9rSm+azoXIma9Ffv7fp+ULVytOkVRtPN5vEjyVUw8b5FOqrZtIbn92zuNlL0fOM6xkr8k+RERdWJOCwAAcItOCwAAcKHOk38T0eEgvQWky2iHXGFivTc0o+S6lHcO+ghXquEgdbjk20pub53GLD3flFlNHHpczptfBcq+0Vgtqon5rOp3SW/Hv1N02zWS26X56wwHNcb+0MwmZaH/Xq4hue4toWPqmemWCHZZ9zOkbE7JzzXxm6kq1BBdakD/HVIOCeWgW85Y+hHS4SFbvrSUpf4bzZ0WAADgAp0WAADgAp0WAADgQuVHnr8i+Wck3ydwUh0fu03yJWwdpEzntLwdOI+q+miYjlVOKfmHEXWIoctYjzKxPkLchUdMrTqPPaqmH3leVvI7TXyOlH2txnlyXbPTTKzzUh6XfKfAcR6QXJc1CGni87i+5H+WfPocJy26912bhP5gRfzXNMd37e8m/rSU3SS5nZ6jS0D8tEYdmrhm+jdP51HZR4FDfx9j5Wrbhib+i5RN8hyycZTkB9SoA488AwAAt+i0AAAAF+i0AAAAF5LNadGx/gclt3MaFiuplF16XFeg1uf6Y54Brzr2d7Hkuqz/XhF1iPFFyf9kYp0j0oVx9kNNrOvydHlOy7SS6zwpO0WgTjtUF66ZdabkG0s+e8SxmmibbqmwnOS6TkYqXbtuk2h5TovO+bNrSsX8L1n/Tjwkecyx2rhmU0n+HxP/UspG1DhPFz6Pdl6n/vanmos0AXdaAACAC3RaAACAC5WX8b9A8s0l10eTjzOxPnb5SNVKNGR3yZ+W3C5vXufxLnW65MckPHYKO0tubwvq9e8yXfVc767r8NFgNYXkT7RSi7CTAmUxw0GflFy3O/h3xLEGpOMk+l/EVHtxdOy/ntdKvmbF4+jfhf0kX0nyOyqeJ5f3JLfDl7rtzYi8VUlONxJv8iPYsY87AABA/+i0AAAAF+i0AAAAFyo/8twUXQ6+jUeey9jxcJ3LcZnkdtn006SsT3KdO7N8oA5NPPZ2i+SfktxuO6B1ryPHI8/XmXgNKdPl6vVRy1RyXTM7H+MZKdPHEfc18eekrM7/aHK1zT7mPKuU6Zyc80y8lpSNlPzHEXXouW2bSH6p5Ppj8VZEJSzdb+FGyb/Z+6FSfNd03pF9HHbvqgctiuJvkm8puc5LslJ9HieXPGYLF/vsrv5d6+J3LUTnW+5oYn3Uu842NzzyDAAA3KLTAgAAXKDTAgAAXOj8nBatwBKSPxxzrBbG/r4u+XyB1x4v+RsR58nVNjs8vpqUpVzSPiTFOLvOabBrSYySMp2KkEuua2av000R79Nl8O+tUYdcbbNbaMxT8lo7T2VkqgoUNdq2oeRXSG5H7/WoOrJvy0+RMl1YKkKO+WO3mXguKbtZ8lVNrNd3I8mviqhDqs+jruFkt5l5pwib18Q3SNk6VStUtPN3Tefk2LbPkPA8zGkBAABu0WkBAAAu0GkBAAAudH5Oiz4PPofkX4g4Vhe28M4lV9vs2OUYKdP9J3JJMc4+NlA2m+Sv9/uq9Pg8+jQU2jZY21UUtC0FndNyoon3Snge5rQAAAC36LQAAAAXPtF2BcocK7kOFyGvph5rzq3zH3QAcKLNvwvcaQEAAC7QaQEAAC7QaQEAAC4EH3kGAADoCu60AAAAF+i0AAAAF+i0AAAAF+i0AAAAF+i0AAAAF+i0AAAAF/4/htX1FXuhE3QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 200 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=392, out_features=50, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=50, out_features=2, bias=True)\n",
      ")\n",
      "Label Accuracy:  0.9465833333333333\n",
      "Color Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, size=[2*14*14, 2]):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(size)-2):\n",
    "            layers.append(torch.nn.Linear(size[i], size[i+1]))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Linear(size[-2], size[-1]))\n",
    "        self.net = torch.nn.Sequential(*layers)\n",
    "        print(self.net)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def tensor_numpy(arrays, device):\n",
    "    out = []\n",
    "    for a in arrays:\n",
    "        out.append(torch.from_numpy(a).float().to(device))\n",
    "    return out\n",
    "    \n",
    "    \n",
    "np.random.seed(1)\n",
    "label_noise = 0.\n",
    "color_noise = None\n",
    "\n",
    "y_train = binarize(y_train, label_noise=label_noise)\n",
    "y_test = binarize(y_test, label_noise=label_noise)\n",
    "\n",
    "X_train, color_train = color_digits(X_train, y_train, color_noise, downsample=True)\n",
    "X_test, color_test = color_digits(X_test, y_test, color_noise, downsample=True)\n",
    "\n",
    "plot_images(X_train)\n",
    "# plot_images(X_test)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "hidden_size = [2*14*14, 50, 2]\n",
    "net = MLP(hidden_size).to(device)\n",
    "\n",
    "tr_x, tr_y, tr_c = tensor_numpy([X_train, y_train, color_train], device)\n",
    "te_x, te_y, te_c = tensor_numpy([X_test, y_test, color_test], device)\n",
    "\n",
    "bs = 256\n",
    "\n",
    "tr_dataset = TensorDataset(tr_x, tr_y, tr_c)\n",
    "tr_loader = DataLoader(tr_dataset, batch_size = bs, shuffle = True)\n",
    "# te_dataset = TensorDataset(te_x, te_y, te_c)\n",
    "# te_loader = DataLoader(te_dataset, batch_size = bs, shuffle = True)\n",
    "\n",
    "loss_label = torch.nn.BCEWithLogitsLoss()\n",
    "loss_color = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "epoch = 10\n",
    "for e in range(epoch):\n",
    "    \n",
    "    for x, y, c in tr_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = net(x)\n",
    "        loss_y = loss_label(out[:,0], y)\n",
    "        loss_c = loss_color(out[:,1], c)\n",
    "        loss = loss_y + loss_c\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "            \n",
    "with torch.no_grad():\n",
    "    test_preds = 1*(net(te_x).detach().cpu().numpy()>0)\n",
    "#     acc_y = (test_preds[:,0] == y_test).mean()\n",
    "#     acc_c = (test_preds[:,1] == color_test).mean()\n",
    "    acc_y = accuracy_score(y_test, test_preds[:,0])\n",
    "    acc_c = accuracy_score(color_test, test_preds[:,1])\n",
    "    print('Label Accuracy: ', acc_y)\n",
    "    print('Color Accuracy: ', acc_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the trained feature extractor to extract features from data that will be used to train and test our classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined environments 1 and 2 data size - used to train our final prediction models\n",
      "40000\n",
      "40000\n",
      "Environment 3 data size - used to test our final prediction models\n",
      "20000\n",
      "20000\n",
      "Printing all the trained model layers\n",
      "[Sequential(\n",
      "  (0): Linear(in_features=392, out_features=50, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=50, out_features=2, bias=True)\n",
      ")]\n",
      "Printing model layers after dropping the output layer for feature extraction\n",
      "Sequential(\n",
      "  (0): Linear(in_features=392, out_features=50, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n",
      "Printing the extracted features - first train features followed by test features shape/size!!!\n",
      "(40000, 51)\n",
      "(20000, 51)\n"
     ]
    }
   ],
   "source": [
    "label_noise = 0.\n",
    "color_noise = None\n",
    "\n",
    "\n",
    "env1_X_train = mnist_train[0][::2]\n",
    "env1_y_train = binarize(mnist_train[1][::2], label_noise=label_noise)\n",
    "\n",
    "env2_X_train = mnist_train[0][1::2]\n",
    "env2_y_train = binarize(mnist_train[1][1::2], label_noise=label_noise)\n",
    "\n",
    "env3_X_train = mnist_test[0]\n",
    "env3_y_train = binarize(mnist_test[1], label_noise=label_noise)\n",
    "\n",
    "envs = [\n",
    "generate_environments(env1_X_train, env1_y_train, 0.2),\n",
    "generate_environments(env2_X_train, env2_y_train, 0.4),\n",
    "generate_environments(env3_X_train, env3_y_train, 0.9)\n",
    "]\n",
    "\n",
    "\n",
    "class feature_extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()   \n",
    "        net.eval()\n",
    "        self.children_list = []\n",
    "        for n,c in net.named_children():\n",
    "            self.children_list.append(c)\n",
    "            \n",
    "        print(\"Printing all the trained model layers\")\n",
    "        print(self.children_list)\n",
    "        self.children_list = self.children_list[0][:2]\n",
    "        print(\"Printing model layers after dropping the output layer for feature extraction\")    \n",
    "        print(self.children_list)\n",
    "        self.net = nn.Sequential(*self.children_list)\n",
    "        self.pretrained = None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def extract_features(model,x,y, device = 'cpu'):\n",
    "    extracted_features = []\n",
    "    labels = []   \n",
    "    with torch.no_grad():\n",
    "        x = x.to(device)\n",
    "        extracted_features = model(x.float())\n",
    "    extracted_features = torch.flatten(extracted_features, 1)\n",
    "    extracted_features_df = pd.DataFrame(extracted_features.numpy())\n",
    "    extracted_features_df[\"target\"] = y.cpu().numpy()\n",
    "    return extracted_features_df\n",
    "\n",
    "\n",
    "\n",
    "train_envs_1_and_2_inputs = torch.cat((torch.from_numpy(envs[0]['images']), torch.from_numpy(envs[1]['images'])), 0)\n",
    "train_envs_1_and_2_targets = torch.cat((torch.from_numpy(envs[0]['labels']), torch.from_numpy(envs[1]['labels'])), 0)\n",
    "\n",
    "print(\"Combined environments 1 and 2 data size - used to train our final prediction models\")\n",
    "print(len(train_envs_1_and_2_inputs))\n",
    "print(len(train_envs_1_and_2_targets))\n",
    "\n",
    "test_inputs =torch.from_numpy(envs[2]['images'])\n",
    "test_targets =torch.from_numpy(envs[2]['labels'])\n",
    "\n",
    "print(\"Environment 3 data size - used to test our final prediction models\")\n",
    "print(len(test_inputs))\n",
    "print(len(test_targets))\n",
    "\n",
    "feature_extractor = feature_extractor()\n",
    "\n",
    "train_extracted_features_df = extract_features(feature_extractor,train_envs_1_and_2_inputs, train_envs_1_and_2_targets)\n",
    "test_extracted_features_df = extract_features(feature_extractor,test_inputs, test_targets)\n",
    "\n",
    "\n",
    "print(\"Printing the extracted features - first train features followed by test features shape/size!!!\")\n",
    "# print(train_extracted_features_df)\n",
    "print(train_extracted_features_df.shape)\n",
    "# print(test_extracted_features_df)\n",
    "print(test_extracted_features_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plain Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the shape of the input!\n",
      "torch.Size([40000, 50])\n",
      "Printing the shape of the target!\n",
      "torch.Size([40000, 1])\n",
      "\n",
      "Plain Logistic Regression Mean Accuracy within training env:  0.8089 std:  0.0\n",
      "Plain Logistic Regression Mean Accuracy on env 3:  0.3733 std:  0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy import vstack\n",
    "from numpy import sqrt\n",
    "\n",
    "# train_data_path = './data/mnist_train_extracted_features.csv'\n",
    "# test_data_path = './data/mnist_test_extracted_features.csv'\n",
    "\n",
    "train_data_path = train_extracted_features_df\n",
    "test_data_path = test_extracted_features_df\n",
    "\n",
    "#***** Obtaining the within training environment test data\n",
    "train, within_test = train_test_split(train_data_path, test_size=0.5, random_state=100)\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "#     data_df = pd.read_csv(path).to_numpy()\n",
    "    data_df = path.to_numpy()\n",
    "\n",
    "    targets = data_df[:, -1] \n",
    "    X = data_df[:, :-1] \n",
    "\n",
    "    # Standardize the data\n",
    "    sscaler = preprocessing.StandardScaler()\n",
    "    sscaler.fit(X)\n",
    "    X = sscaler.transform(X)\n",
    "\n",
    "\n",
    "    X_torch = torch.from_numpy(X)\n",
    "    targets_torch = torch.from_numpy(targets)\n",
    "    return X_torch, targets_torch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(d,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_hat = self.linear(x)\n",
    "        return torch.sigmoid(y_hat)\n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "# train the model\n",
    "def train_model(inputs, targets, model):\n",
    "    # define the optimization\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    \n",
    "    for epoch in range(100):        \n",
    "        optimizer.zero_grad() \n",
    "        y_hat = model(inputs.float())\n",
    "        loss = criterion(y_hat.float(), targets.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "        \n",
    "\n",
    "# evaluate the model\n",
    "def model_eval(inputs, targets, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    yhat = model.forward(inputs.float())\n",
    "    yhat = np.where(yhat.detach().numpy() < 0.5, 0, 1)\n",
    "    actual = targets.detach().cpu().numpy()\n",
    "    actual = actual.reshape((len(actual), 1))\n",
    "    yhat = yhat.reshape((len(yhat), 1))\n",
    "\n",
    "    predictions.append(yhat)\n",
    "    actuals.append(actual)\n",
    "\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "#     calculate accuracy\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "#     acc = accuracy_score(actual, yhat)\n",
    "    return acc\n",
    "\n",
    "\n",
    "X_torch_train, targets_torch_train = read_data(train_data_path)\n",
    "X_torch_test, targets_torch_test = read_data(test_data_path)\n",
    "X_torch_test_within, targets_torch_test_within = read_data(within_test)\n",
    "\n",
    "\n",
    "targets_torch_train = targets_torch_train.reshape(-1,1)\n",
    "targets_torch_test = targets_torch_test.reshape(-1,1)\n",
    "targets_torch_test_within = targets_torch_test_within.reshape(-1,1)\n",
    "\n",
    "d = X_torch_train.shape[1]\n",
    "\n",
    "print(\"Printing the shape of the input!\")\n",
    "print(X_torch_train.shape)\n",
    "\n",
    "print(\"Printing the shape of the target!\")\n",
    "print(targets_torch_train.shape)\n",
    "\n",
    "model = LogisticRegression(d) \n",
    "\n",
    "train_model(X_torch_train, targets_torch_train, model)\n",
    "\n",
    "\n",
    "accuracy_list = []\n",
    "within_accuracy_list = []\n",
    "for i in range(10):\n",
    "    accuracy = model_eval(X_torch_test, targets_torch_test, model)\n",
    "    accuracy_within = model_eval(X_torch_test_within, targets_torch_test_within, model)\n",
    "    accuracy_list.append(accuracy)\n",
    "    within_accuracy_list.append(accuracy_within)\n",
    "print()\n",
    "print('Plain Logistic Regression Mean Accuracy within training env: ', np.mean(within_accuracy_list).round(4), \n",
    "      'std: ', np.std(within_accuracy_list).round(3))\n",
    "print('Plain Logistic Regression Mean Accuracy on env 3: ', np.mean(accuracy_list).round(4), 'std: ', \n",
    "      np.std(accuracy_list).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifier with NOTEARS (without threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DAG!!!!!\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 6.52426340e-09\n",
      "  3.57930146e-06 2.53869619e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.58295024e-07 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.24394150e-07 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "Linear Model with NOTEARS Accuracy within training env: 0.877\n",
      "Linear Model with NOTEARS Accuracy on env 3: 0.683\n",
      "\n",
      "Linear Model with NOTEARS Mean Accuracy within training env:  0.8773 std:  0.0\n",
      "Linear Model with NOTEARS Mean Accuracy on env 3:  0.6826 std:  0.0\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################################################\n",
    "# Some parts of the code in this cell are from: Zheng, Xun, et al. \"Dags with no tears: Continuous optimization for \n",
    "# structure learning.\" Advances in Neural Information Processing Systems 31 (2018). \n",
    "# Their code is available here https://github.com/xunzheng/notears\n",
    "######################################################################################################################\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.linalg as slin\n",
    "import scipy.optimize as sopt\n",
    "from scipy.special import expit as sigmoid\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from numpy import vstack\n",
    "from numpy import sqrt\n",
    "\n",
    "\n",
    "# train_data_path = './data/mnist_train_extracted_features.csv'\n",
    "# test_data_path = './data/mnist_test_extracted_features.csv'\n",
    "\n",
    "train_data_path = train_extracted_features_df\n",
    "test_data_path = test_extracted_features_df\n",
    "\n",
    "#***** Obtaining the within training environment test data\n",
    "train, within_test = train_test_split(train_data_path, test_size=0.5, random_state=100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "#     data = pd.read_csv(path).to_numpy()\n",
    "    data = path.to_numpy()\n",
    "    \n",
    "    X = data.copy()\n",
    "    targets = X[:, -1] \n",
    "\n",
    "    # Standardize the data\n",
    "    sscaler = preprocessing.StandardScaler()\n",
    "    sscaler.fit(data)\n",
    "    data = sscaler.transform(data)\n",
    "    return data,targets\n",
    "\n",
    "\n",
    "def notears_linear(X, y, lambda1, loss_type, max_iter=100, h_tol=1e-8, rho_max=1e+16, w_threshold=0.3):\n",
    "    \"\"\"Solve min_W L(W; X) + lambda1 ‖W‖_1 s.t. h(W) = 0 using augmented Lagrangian.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): [n, d] sample matrix\n",
    "        lambda1 (float): l1 penalty parameter\n",
    "        loss_type (str): l2, logistic, poisson\n",
    "        max_iter (int): max num of dual ascent steps\n",
    "        h_tol (float): exit if |h(w_est)| <= htol\n",
    "        rho_max (float): exit if rho >= rho_max\n",
    "        w_threshold (float): drop edge if |weight| < threshold\n",
    "\n",
    "    Returns:\n",
    "        W_est (np.ndarray): [d, d] estimated DAG\n",
    "    \"\"\"\n",
    "    def _loss(W):\n",
    "        \"\"\"Evaluate value and gradient of loss.\"\"\"\n",
    "        M = X @ W\n",
    "        \n",
    "        yhat = M[:, -1]\n",
    "        targets = y\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        \n",
    "        yhat = torch.from_numpy(yhat)\n",
    "        targets = torch.from_numpy(targets)\n",
    "        \n",
    "        yhat = torch.sigmoid(yhat) \n",
    "        \n",
    "        yhat = yhat.reshape(-1,1)\n",
    "        targets = targets.reshape(-1,1)\n",
    "        \n",
    "        if loss_type == 'l2':\n",
    "            R = X - M\n",
    "            loss_pred = criterion(yhat.float(), targets.float())\n",
    "            loss = 0.5 / X.shape[0] * (R ** 2).sum()\n",
    "            G_loss = - 1.0 / X.shape[0] * X.T @ R\n",
    "        elif loss_type == 'logistic':\n",
    "            loss_pred = criterion(yhat, targets)\n",
    "            loss = 1.0 / X.shape[0] * (np.logaddexp(0, M) - X * M).sum()\n",
    "            G_loss = 1.0 / X.shape[0] * X.T @ (sigmoid(M) - X)\n",
    "        elif loss_type == 'poisson':\n",
    "            loss_pred = criterion(yhat, targets)\n",
    "            S = np.exp(M)\n",
    "            loss = 1.0 / X.shape[0] * (S - X * M).sum()\n",
    "            G_loss = 1.0 / X.shape[0] * X.T @ (S - X)\n",
    "        else:\n",
    "            raise ValueError('unknown loss type')\n",
    "        return loss, loss_pred, G_loss\n",
    "\n",
    "    def _h(W):\n",
    "        \"\"\"Evaluate value and gradient of acyclicity constraint.\"\"\"\n",
    "        E = slin.expm(W * W)  # (Zheng et al. 2018)\n",
    "        h = np.trace(E) - d\n",
    "        #     # A different formulation, slightly faster at the cost of numerical stability\n",
    "        #     M = np.eye(d) + W * W / d  # (Yu et al. 2019)\n",
    "        #     E = np.linalg.matrix_power(M, d - 1)\n",
    "        #     h = (E.T * M).sum() - d\n",
    "        G_h = E.T * W * 2\n",
    "        return h, G_h\n",
    "\n",
    "    def _adj(w):\n",
    "        \"\"\"Convert doubled variables ([2 d^2] array) back to original variables ([d, d] matrix).\"\"\"\n",
    "        return (w[:d * d] - w[d * d:]).reshape([d, d])\n",
    "\n",
    "    def _func(w):\n",
    "        \"\"\"Evaluate value and gradient of augmented Lagrangian for doubled variables ([2 d^2] array).\"\"\"\n",
    "        W = _adj(w)\n",
    "        loss, loss_pred, G_loss = _loss(W)\n",
    "        h, G_h = _h(W)\n",
    "        obj = loss + loss_pred + 0.5 * rho * h * h + alpha * h + lambda1 * w.sum()\n",
    "        G_smooth = G_loss + (rho * h + alpha) * G_h\n",
    "        g_obj = np.concatenate((G_smooth + lambda1, - G_smooth + lambda1), axis=None)\n",
    "        return obj, g_obj\n",
    "\n",
    "    n, d = X.shape\n",
    "    w_est, rho, alpha, h = np.zeros(2 * d * d), 1.0, 0.0, np.inf  # double w_est into (w_pos, w_neg)\n",
    "    bnds = [(0, 0) if i == j else (0, None) for _ in range(2) for i in range(d) for j in range(d)]\n",
    "    if loss_type == 'l2':\n",
    "        X = X - np.mean(X, axis=0, keepdims=True)\n",
    "    for _ in range(max_iter):\n",
    "        w_new, h_new = None, None\n",
    "        while rho < rho_max:\n",
    "            sol = sopt.minimize(_func, w_est, method='L-BFGS-B', jac=True, bounds=bnds)\n",
    "            w_new = sol.x\n",
    "            h_new, _ = _h(_adj(w_new))\n",
    "            if h_new > 0.25 * h:\n",
    "                rho *= 10\n",
    "            else:\n",
    "                break\n",
    "        w_est, h = w_new, h_new\n",
    "        alpha += rho * h\n",
    "        if h <= h_tol or rho >= rho_max:\n",
    "            break\n",
    "    W_est = _adj(w_est)\n",
    "#     W_est[np.abs(W_est) < w_threshold] = 0\n",
    "    return W_est\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "def model_eval(inputs, targets, W):\n",
    "    reconstructed_inputs = inputs @ W\n",
    "    \n",
    "    yhat = torch.from_numpy(reconstructed_inputs[:, -1])\n",
    "    targets = torch.from_numpy(targets)\n",
    "    \n",
    "    yhat = torch.sigmoid(yhat) \n",
    "    yhat = np.where(yhat.detach().numpy() < 0.5, 0, 1)\n",
    "    \n",
    "    actual = targets.cpu().numpy()\n",
    "    actual = actual.reshape((len(actual), 1))\n",
    "    yhat = yhat.reshape((len(yhat), 1))\n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(actual, yhat)\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    X_train, train_targets = read_data(train_data_path)\n",
    "    X_test, test_targets = read_data(test_data_path)\n",
    "    \n",
    "    X_test_within, targets_test_within = read_data(within_test)\n",
    "    W_est = notears_linear(X_train,train_targets, lambda1=0.1, loss_type='l2')\n",
    "    \n",
    "    print(\"Final DAG!!!!!\")\n",
    "    print(W_est)\n",
    "    \n",
    "    accuracy = model_eval(X_test, test_targets, W_est)\n",
    "    accuracy_within = model_eval(X_test_within, targets_test_within, W_est)\n",
    "    print('Linear Model with NOTEARS Accuracy within training env: %.3f' % accuracy_within)\n",
    "    print('Linear Model with NOTEARS Accuracy on env 3: %.3f' % accuracy)\n",
    "    \n",
    "    np.savetxt('W_est.csv', W_est, delimiter=',')\n",
    "    \n",
    "    accuracy_list_notears = []\n",
    "    within_accuracy_list_notears = []\n",
    "    for i in range(10):\n",
    "        accuracy_notears = model_eval(X_test, test_targets, W_est)\n",
    "        accuracy_within_notears = model_eval(X_test_within, targets_test_within, W_est)\n",
    "        accuracy_list_notears.append(accuracy_notears)\n",
    "        within_accuracy_list_notears.append(accuracy_within_notears)\n",
    "    print()\n",
    "    print('Linear Model with NOTEARS Mean Accuracy within training env: ', np.mean(within_accuracy_list_notears).round(4), \n",
    "          'std: ', np.std(within_accuracy_list_notears).round(3))\n",
    "    print('Linear Model with NOTEARS Mean Accuracy on env 3: ', np.mean(accuracy_list_notears).round(4), 'std: ', \n",
    "          np.std(accuracy_list_notears).round(3))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of causal features and features with high correlation coefficients to color and label targets in the feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 2.0857e-38, -2.7463e-39, -1.7912e-40,  ...,  1.1575e-01,\n",
       "          -1.3991e-38, -5.7981e-38],\n",
       "         [-2.2110e-38,  2.3893e-38, -4.4334e-38,  ...,  1.6731e-01,\n",
       "           2.0864e-39, -4.9193e-38],\n",
       "         [ 1.4948e-38, -4.0035e-38, -1.7797e-38,  ..., -7.9866e-02,\n",
       "          -9.5270e-40, -5.4243e-38],\n",
       "         ...,\n",
       "         [-3.8401e-38,  4.7179e-38,  5.7980e-39,  ..., -1.8187e-01,\n",
       "          -1.6029e-38, -5.4607e-38],\n",
       "         [ 2.4071e-38,  4.8597e-38, -2.8502e-38,  ...,  1.8759e-01,\n",
       "          -3.0321e-38, -1.7593e-38],\n",
       "         [ 3.8510e-38,  1.8353e-38, -3.8616e-38,  ...,  9.4795e-02,\n",
       "          -1.5059e-38,  6.5034e-38]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1729, 0.1016, 0.0627, 0.2844, 0.1683, 0.1691, 0.0962, 0.0997, 0.1515,\n",
       "         0.0697, 0.1234, 0.1903, 0.0403, 0.0715, 0.1876, 0.1107, 0.3390, 0.1768,\n",
       "         0.1012, 0.2374, 0.2878, 0.1572, 0.1927, 0.0669, 0.0771, 0.1708, 0.1488,\n",
       "         0.1921, 0.1012, 0.1590, 0.1987, 0.1574, 0.0890, 0.2258, 0.0568, 0.1038,\n",
       "         0.1992, 0.0544, 0.0470, 0.1386, 0.1847, 0.1372, 0.1073, 0.1796, 0.0986,\n",
       "         0.0173, 0.0410, 0.0703, 0.2309, 0.1985], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.5056,  0.6724, -0.2891,  0.3458,  0.2991,  0.1965, -0.7111, -0.8293,\n",
       "          -0.4711, -0.2584,  0.0472,  0.2451, -0.5981, -0.2768,  0.0043,  0.3729,\n",
       "           0.1183,  0.1348, -0.3776,  0.0327,  0.2043, -0.4849,  0.0072,  0.4322,\n",
       "          -0.4582, -0.7507, -0.3659,  0.0178, -0.1759, -0.4739,  0.3198,  0.4355,\n",
       "           0.3654,  0.3246, -0.8624, -0.5349, -0.5313, -0.6755,  0.3984, -0.2899,\n",
       "           0.4855,  0.0113,  0.3361,  0.3329, -0.4256, -0.8852,  0.3647, -0.5089,\n",
       "           0.4267,  0.1022],\n",
       "         [-0.2518,  0.1840, -0.2910,  0.1979, -0.2920,  0.3115, -0.1319, -0.1827,\n",
       "           0.1621,  0.2204,  0.3170,  0.2880, -0.2181,  0.2295,  0.2376, -0.2668,\n",
       "           0.2890,  0.3463,  0.2101, -0.3307,  0.2132, -0.2617, -0.3406, -0.2243,\n",
       "           0.2784, -0.0778, -0.2495, -0.2573,  0.3624, -0.2678,  0.2980, -0.2244,\n",
       "          -0.2587,  0.2121,  0.0405,  0.1201,  0.2304, -0.2252, -0.4474, -0.2973,\n",
       "           0.2043,  0.2655, -0.3556, -0.3159, -0.2532, -0.2526, -0.2958,  0.1341,\n",
       "           0.2443,  0.2991]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0241, -0.0573], requires_grad=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the weights of the feature extractor\n",
    "all_weights = list(net.parameters())\n",
    "all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Label Coeficients:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5056,  0.6724, -0.2891,  0.3458,  0.2991,  0.1965, -0.7111, -0.8293,\n",
       "        -0.4711, -0.2584,  0.0472,  0.2451, -0.5981, -0.2768,  0.0043,  0.3729,\n",
       "         0.1183,  0.1348, -0.3776,  0.0327,  0.2043, -0.4849,  0.0072,  0.4322,\n",
       "        -0.4582, -0.7507, -0.3659,  0.0178, -0.1759, -0.4739,  0.3198,  0.4355,\n",
       "         0.3654,  0.3246, -0.8624, -0.5349, -0.5313, -0.6755,  0.3984, -0.2899,\n",
       "         0.4855,  0.0113,  0.3361,  0.3329, -0.4256, -0.8852,  0.3647, -0.5089,\n",
       "         0.4267,  0.1022], grad_fn=<SelectBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Color Coeficients:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2518,  0.1840, -0.2910,  0.1979, -0.2920,  0.3115, -0.1319, -0.1827,\n",
       "         0.1621,  0.2204,  0.3170,  0.2880, -0.2181,  0.2295,  0.2376, -0.2668,\n",
       "         0.2890,  0.3463,  0.2101, -0.3307,  0.2132, -0.2617, -0.3406, -0.2243,\n",
       "         0.2784, -0.0778, -0.2495, -0.2573,  0.3624, -0.2678,  0.2980, -0.2244,\n",
       "        -0.2587,  0.2121,  0.0405,  0.1201,  0.2304, -0.2252, -0.4474, -0.2973,\n",
       "         0.2043,  0.2655, -0.3556, -0.3159, -0.2532, -0.2526, -0.2958,  0.1341,\n",
       "         0.2443,  0.2991], grad_fn=<SelectBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract coeficients of features for the label and coeficients of features for the color\n",
    "label_coefficients = all_weights[2][0]\n",
    "print(\"Printing Label Coeficients:\")\n",
    "display(label_coefficients)\n",
    "color_coefficients = all_weights[2][1]\n",
    "print(\"Printing Color Coeficients:\")\n",
    "display(color_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out indeces of sorted features from highest to lowest coefficients for label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([45, 34,  7, 25,  6, 37,  1, 12, 35, 36, 47,  0, 40, 21, 29,  8, 24, 31,\n",
       "        23, 48, 44, 38, 18, 15, 26, 32, 46,  3, 42, 43, 33, 30,  4, 39,  2, 13,\n",
       "         9, 11, 20,  5, 28, 17, 16, 49, 10, 19, 27, 41, 22, 14])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out feature correlation coefficients from highest to lowest for label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.8852, -0.8624, -0.8293, -0.7507, -0.7111, -0.6755,  0.6724, -0.5981,\n",
       "        -0.5349, -0.5313, -0.5089,  0.5056,  0.4855, -0.4849, -0.4739, -0.4711,\n",
       "        -0.4582,  0.4355,  0.4322,  0.4267, -0.4256,  0.3984, -0.3776,  0.3729,\n",
       "        -0.3659,  0.3654,  0.3647,  0.3458,  0.3361,  0.3329,  0.3246,  0.3198,\n",
       "         0.2991, -0.2899, -0.2891, -0.2768, -0.2584,  0.2451,  0.2043,  0.1965,\n",
       "        -0.1759,  0.1348,  0.1183,  0.1022,  0.0472,  0.0327,  0.0178,  0.0113,\n",
       "         0.0072,  0.0043], grad_fn=<IndexBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out indeces of sorted features from highest to lowest coefficients for color\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([38, 28, 42, 17, 22, 19, 10, 43,  5, 49, 30, 39, 46,  4,  2, 16, 11, 24,\n",
       "        29, 15, 41, 21, 32, 27, 44, 45,  0, 26, 48, 14, 36, 13, 37, 31, 23,  9,\n",
       "        12, 20, 33, 18, 40,  3,  1,  7,  8, 47,  6, 35, 25, 34])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out feature correlation coefficients from highest to lowest for label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.4474,  0.3624, -0.3556,  0.3463, -0.3406, -0.3307,  0.3170, -0.3159,\n",
       "         0.3115,  0.2991,  0.2980, -0.2973, -0.2958, -0.2920, -0.2910,  0.2890,\n",
       "         0.2880,  0.2784, -0.2678, -0.2668,  0.2655, -0.2617, -0.2587, -0.2573,\n",
       "        -0.2532, -0.2526, -0.2518, -0.2495,  0.2443,  0.2376,  0.2304,  0.2295,\n",
       "        -0.2252, -0.2244, -0.2243,  0.2204, -0.2181,  0.2132,  0.2121,  0.2101,\n",
       "         0.2043,  0.1979,  0.1840, -0.1827,  0.1621,  0.1341, -0.1319,  0.1201,\n",
       "        -0.0778,  0.0405], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorted features from highest to lowest absolute value of coefficients for label\n",
    "Sorted_features_highest_to_lowest_coefs_label = torch.argsort(label_coefficients.abs(), descending=True)\n",
    "print(\"Printing out indeces of sorted features from highest to lowest coefficients for label\")\n",
    "display(Sorted_features_highest_to_lowest_coefs_label)\n",
    "print(\"Printing out feature correlation coefficients from highest to lowest for label\")\n",
    "display(label_coefficients[Sorted_features_highest_to_lowest_coefs_label])\n",
    "\n",
    "\n",
    "\n",
    "# Sorted features from highest to lowest absolute value of coefficients for color\n",
    "Sorted_features_highest_to_lowest_coefs_color = torch.argsort(color_coefficients.abs(), descending=True)\n",
    "print(\"Printing out indeces of sorted features from highest to lowest coefficients for color\")\n",
    "display(Sorted_features_highest_to_lowest_coefs_color)\n",
    "print(\"Printing out feature correlation coefficients from highest to lowest for label\")\n",
    "color_coefficients[Sorted_features_highest_to_lowest_coefs_color]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_with_direct_links_to_the_label1 = W_est[0,:][1:]\n",
    "display(features_with_direct_links_to_the_label1.shape)\n",
    "features_with_direct_links_to_the_label2 = W_est[:,-1][1:]\n",
    "features_with_direct_links_to_the_label2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out indeces of sorted features from most causal to least causal group 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([37, 21,  9, 13, 26, 18, 40, 15, 30, 29, 14,  3, 42, 36, 25, 49, 31, 48,\n",
       "        32, 33, 34, 35, 47, 46, 38, 39, 45, 44, 43, 41, 12,  1,  2,  4,  5,  6,\n",
       "         7,  8, 10, 11, 28, 16, 17, 19, 20, 22, 23, 24,  0, 27])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out feature causal coefficients from highest to lowest from group 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.09276370e-01,  6.52533576e-02, -3.00423820e-02, -8.17794465e-04,\n",
       "        2.70298929e-04,  2.29965689e-05, -2.76834074e-06, -9.50475676e-07,\n",
       "        4.58732112e-07, -3.38889570e-07,  1.07701553e-07,  6.62057673e-08,\n",
       "        1.50548159e-08,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Printing out indeces of sorted features from most causal to least causal group 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  6, 24, 36,  2, 44, 28, 35, 45, 10, 32,  5, 30, 40, 29, 31, 33, 34,\n",
       "        37, 38, 39, 25, 41, 42, 43, 46, 47, 48, 49, 15,  1,  3,  4,  7,  8,  9,\n",
       "        11, 12, 13, 14, 27, 16, 17, 18, 19, 20, 21, 22, 23, 26])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out feature causal coefficients from highest to lowest from group 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.53869619e-01, -2.18190999e-01, -1.65660457e-01, -1.55962351e-01,\n",
       "        1.05332620e-01, -9.54565934e-02, -2.33034880e-02, -2.23929140e-02,\n",
       "        1.72795585e-02,  2.28708710e-03,  1.56002754e-04, -3.47380157e-07,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sorted features from most causal to least causal group 1\n",
    "sorted_features_most__causal_to_least1 = torch.argsort(torch.from_numpy(features_with_direct_links_to_the_label1).abs(),descending=True)\n",
    "print(\"Printing out indeces of sorted features from most causal to least causal group 1\")\n",
    "display(sorted_features_most__causal_to_least1)\n",
    "print(\"Printing out feature causal coefficients from highest to lowest from group 1\")\n",
    "display(features_with_direct_links_to_the_label1[sorted_features_most__causal_to_least1])\n",
    "\n",
    "print()\n",
    "\n",
    "# Sorted features from most causal to least causal group 2\n",
    "sorted_features_most__causal_to_least2 = torch.argsort(torch.from_numpy(features_with_direct_links_to_the_label2).abs(), descending=True)\n",
    "print(\"Printing out indeces of sorted features from most causal to least causal group 2\")\n",
    "display(sorted_features_most__causal_to_least2)\n",
    "print(\"Printing out feature causal coefficients from highest to lowest from group 2\")\n",
    "display(features_with_direct_links_to_the_label2[sorted_features_most__causal_to_least2])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  5, 14, 17, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
       "       38, 39, 43, 46])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_causal_feature_indeces = np.union1d(sorted_features_most__causal_to_least1.numpy()[:16], sorted_features_most__causal_to_least2.numpy()[:16])  \n",
    "\n",
    "all_causal_feature_indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 14, 17, 25, 27, 29, 31, 35, 36, 38, 39, 43, 46])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying features that are correlated to label, but are also in the causal feature set to label\n",
    "\n",
    "label_corr_and_causal_features_intersection = np.intersect1d(all_causal_feature_indeces, Sorted_features_highest_to_lowest_coefs_label.numpy()[:26] )\n",
    "label_corr_and_causal_features_intersection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  5, 17, 27, 28, 30, 32, 34, 37, 43, 46])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying features that are correlated to color, but are also in the causal feature set to label \n",
    "\n",
    "color_corr_and_causal_features_intersection = np.intersect1d(all_causal_feature_indeces, Sorted_features_highest_to_lowest_coefs_color.numpy()[:26] )\n",
    "color_corr_and_causal_features_intersection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 18, 22, 27, 41, 43, 46])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying features that are correlated to both color and label\n",
    "\n",
    "color_corr_and_label_corr= np.intersect1d(Sorted_features_highest_to_lowest_coefs_label.numpy()[:26], Sorted_features_highest_to_lowest_coefs_color.numpy()[:26] )\n",
    "color_corr_and_label_corr\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:castle_env]",
   "language": "python",
   "name": "conda-env-castle_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
