{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image \n",
    "from scipy import ndimage, misc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from image_feature_extractor import Img2Vec\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download CIFAR 10 data form torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10('~/datasets/cifar', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10('~/datasets/cifar', train=False, download=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_contrast(images_data, contrast_factor):\n",
    "    to_tensor = transforms.ToTensor()   \n",
    "    images_list = [to_tensor(im) for im in images_data]\n",
    "    images = torch.stack(images_list)\n",
    "    contrasted_images = F.adjust_contrast(images, contrast_factor)\n",
    "    contrasted_images = np.array(np.stack([transforms.ToPILImage()(im) for im in contrasted_images]))\n",
    "    return contrasted_images\n",
    "\n",
    "def apply_rotation(images_data, angle=30):\n",
    "    rotated_images = []\n",
    "    for img in images_data:\n",
    "        rotated_image = ndimage.rotate(img, angle, reshape=False)\n",
    "        rotated_images.append(rotated_image)\n",
    "    rotated_images = np.array(rotated_images)\n",
    "    return rotated_images\n",
    "\n",
    "def blur_images(images_data, sigma=1):\n",
    "    blurred_images = []\n",
    "    for img in images_data:\n",
    "        blurred_image = gaussian_filter(img, sigma)\n",
    "        blurred_images.append(blurred_image)\n",
    "    blurred_images = np.array(blurred_images)\n",
    "    return blurred_images\n",
    "\n",
    "\n",
    "# Generate a list of original and duplicate modified images: every original image has a duplicate which is \n",
    "# the modified original image.\n",
    "def generate_list_of_original_and_its_duplicate_modified_images(image_set, mod_factor, mod_type=\"contrast\"):\n",
    "    original_labels = np.zeros(len(image_set.data))\n",
    "    modified_labels = np.ones(len(image_set.data))\n",
    "    \n",
    "    modified_images = None\n",
    "    \n",
    "    if mod_type==\"contrast\":\n",
    "        modified_images = apply_contrast(image_set.data, mod_factor) \n",
    "        \n",
    "    elif mod_type==\"rotation\":\n",
    "        modified_images = apply_rotation(image_set.data, mod_factor)\n",
    "    \n",
    "    elif mod_type==\"blur\":\n",
    "        modified_images = blur_images(image_set.data, mod_factor)\n",
    "\n",
    "    original_and_modified_images = np.concatenate((image_set.data, modified_images), axis=0)\n",
    "    modification_labels = np.concatenate((original_labels, modified_labels), axis=None)\n",
    "    image_labels = np.concatenate((image_set.targets, image_set.targets), axis=None)        \n",
    "    return modified_images, original_and_modified_images, modification_labels, image_labels\n",
    "\n",
    "\n",
    "\n",
    "# Generate a list of original and copies of its modified images combined: every original image has other \n",
    "# copies of itself on which different types of transformations/modifications have been applied. \n",
    "def generate_list_of_original_and_copies_of_its_modified_images(image_set, contrast_factor=0.3, angle=30, sigma=1):\n",
    "    original_labels = np.zeros(len(image_set.data))\n",
    "    modified_labels1 = np.ones(len(image_set.data))\n",
    "    modified_labels2 = np.array([2]*len(image_set.data))\n",
    "    modified_labels3 = np.array([3]*len(image_set.data))\n",
    "\n",
    "    modified_images1 = apply_contrast(image_set.data, contrast_factor) \n",
    "\n",
    "    modified_images2 = apply_rotation(image_set.data, angle)\n",
    "    \n",
    "    modified_images3 = blur_images(image_set.data, sigma)\n",
    "\n",
    "    original_and_modified_images = np.concatenate((image_set.data, modified_images1, modified_images2,modified_images3), axis=0)\n",
    "    modification_labels = np.concatenate((original_labels, modified_labels1, modified_labels2,modified_labels3), axis=None)\n",
    "    image_labels = np.concatenate((image_set.targets, image_set.targets, image_set.targets,image_set.targets), axis=None)        \n",
    "    return original_and_modified_images, modification_labels, image_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# used to binarize the target variable\n",
    "def binarize(y):    \n",
    "    y = np.copy(y) > 5\n",
    "    return y.astype(int)\n",
    "\n",
    "def correlate_label_with_img_modification(image_dataset, mod_factor, mod_percent= 0.1, \n",
    "                                          binarize_label=True, mod_type=\"contrast\"):\n",
    "    y = binarize(image_dataset.targets)\n",
    "    mod_labels = np.logical_xor(y, np.random.binomial(1, mod_percent, size=len(y)))\n",
    "    \n",
    "    images_to_be_modified = image_dataset.data[mod_labels]\n",
    "    images_to_be_left_alone = image_dataset.data[~mod_labels]\n",
    "    \n",
    "    all_img_labels = None\n",
    "    \n",
    "    if binarize_label:\n",
    "        modified_imgs_labels = y[mod_labels]\n",
    "        unmodified_imgs_labels = y[~mod_labels]\n",
    "        all_img_labels = np.concatenate((modified_imgs_labels, unmodified_imgs_labels), axis=None)\n",
    "    else:\n",
    "        modified_imgs_labels = np.array(image_dataset.targets)[mod_labels]\n",
    "        unmodified_imgs_labels = np.array(image_dataset.targets)[~mod_labels]\n",
    "        all_img_labels = np.concatenate((modified_imgs_labels, unmodified_imgs_labels), axis=None)    \n",
    "    \n",
    "    all_images = None\n",
    "    \n",
    "    if mod_type == \"contrast\":\n",
    "        modified_images = apply_contrast(images_to_be_modified, mod_factor)\n",
    "        all_images = np.concatenate((modified_images, images_to_be_left_alone), axis=0)                    \n",
    "        \n",
    "    elif mod_type==\"rotation\":\n",
    "        modified_images = apply_rotation(images_to_be_modified, mod_factor)\n",
    "        all_images = np.concatenate((modified_images, images_to_be_left_alone), axis=0)\n",
    "        \n",
    "    return all_images, all_img_labels, mod_labels.astype(int)\n",
    "\n",
    "\n",
    "# Function to extract image features    \n",
    "def get_features(images, batch_size):\n",
    "    Z_list = []\n",
    "#     img2vec = Img2Vec(model=\"resnet50\")\n",
    "    img2vec = Img2Vec()\n",
    "    for first in range(0, len(images), batch_size):\n",
    "        images_subset = images[first:first+batch_size]\n",
    "        Z_subset = img2vec.get_vec(images_subset)\n",
    "        Z_list.append(Z_subset)\n",
    "    Z = np.vstack(Z_list)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Blurred Image. Change sigma value to increase or decrease blur strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(121)  \n",
    "ax1.set_title(\"Original\")\n",
    "ax2 = fig.add_subplot(122) \n",
    "ax2.set_title(\"Blurred\")\n",
    "img = test_dataset.data[0]\n",
    "blurred = gaussian_filter(img, sigma=1)\n",
    "ax1.imshow(img)\n",
    "ax2.imshow(blurred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 32, 32, 3)\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "contrast_factor = 0.3\n",
    "angle = 15\n",
    "sigma = 1\n",
    "batch_size = 64\n",
    "dist_value = 1.0\n",
    "\n",
    "# Creating a set of images to be used to obtain L\n",
    "all_images, mod_labels, img_labels = generate_list_of_original_and_copies_of_its_modified_images(\n",
    "    train_dataset, contrast_factor, angle, sigma)\n",
    "\n",
    "\n",
    "# Creating sets of images in a way that correlates the way images are modified with label\n",
    "train_imgs, train_labels2, train_mod_labels2 = correlate_label_with_img_modification(\n",
    "    train_dataset, contrast_factor, mod_percent= dist_value, binarize_label=False, mod_type=\"contrast\")\n",
    "\n",
    "test_imgs_indist, test_labels2_indist, test_mod_labels2_indist = correlate_label_with_img_modification(\n",
    "    test_dataset, contrast_factor, mod_percent= dist_value, binarize_label=False, mod_type=\"contrast\")\n",
    "\n",
    "test_imgs_ood, test_labels2_ood, test_mod_labels2_ood = correlate_label_with_img_modification(\n",
    "    test_dataset, contrast_factor, mod_percent= 1-dist_value, binarize_label=False, mod_type=\"contrast\")\n",
    "\n",
    "# creating duplicates of contrasted and uncontrasted images\n",
    "t_contr_imgs, t_imgs, t_mod_labels, t_labels = generate_list_of_original_and_its_duplicate_modified_images(\n",
    "    test_dataset, contrast_factor,mod_type=\"contrast\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(all_images.shape)\n",
    "print(train_imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_labels[mod_labels==3]\n",
    "\n",
    "# Extract image features\n",
    "Z = get_features(all_images, batch_size)\n",
    "Z_train = get_features(train_imgs, batch_size)\n",
    "Z_test_indist= get_features(test_imgs_indist, batch_size)\n",
    "Z_test_ood= get_features(test_imgs_ood, batch_size)\n",
    "\n",
    "Z_test_original = get_features(test_dataset.data, batch_size)\n",
    "Z_test_contrasted = get_features(t_contr_imgs, batch_size)\n",
    "Z_test_og_contrasted = get_features(t_imgs, batch_size)\n",
    "\n",
    "# mod_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining prediction coefficients and prediction accuracy of transformations done on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast coefficients shape\n",
      "(512, 1)\n",
      "Train Contrast prediction accuracy:  0.9944\n",
      "Test Contrast prediction accuracy:  0.9923\n",
      "Train rotation prediction accuracy:  0.99844\n"
     ]
    }
   ],
   "source": [
    "# Using sklearn Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# not_1_and_2 = (mod_labels !=1) & (mod_labels !=2) # 0 (original) and 3 (blurred)\n",
    "not_1_and_3 = (mod_labels !=1) & (mod_labels !=3) # 0 (original) and 2 (rotated)\n",
    "not_2_and_3 = (mod_labels !=2) & (mod_labels !=3) # 0 (original) and 1 (contrasted)\n",
    "\n",
    "# Z_og_blurred = Z[not_1_and_2]\n",
    "# blur_labels = mod_labels[not_1_and_2]\n",
    "\n",
    "Z_og_rotated = Z[not_1_and_3]\n",
    "rotation_labels = mod_labels[not_1_and_3]\n",
    "\n",
    "Z_og_contrasted = Z[not_2_and_3]\n",
    "contrast_labels =  mod_labels[not_2_and_3]\n",
    "\n",
    "\n",
    "\n",
    "lr_model_contrast = LogisticRegression(random_state=0).fit(Z_og_contrasted, contrast_labels)\n",
    "contrast_coefficients = lr_model_contrast.coef_.reshape(-1,1)\n",
    "theta_1 = contrast_coefficients / np.linalg.norm(contrast_coefficients)\n",
    "\n",
    "theta_1_theta_1_T = theta_1 @ theta_1.T\n",
    "d = theta_1_theta_1_T.shape[0]\n",
    "I = np.identity(d)\n",
    "I_minus_theta_1_theta_1_T = I-theta_1_theta_1_T\n",
    "\n",
    "\n",
    "lr_model_rotation = LogisticRegression(random_state=0).fit((Z_og_rotated @ I_minus_theta_1_theta_1_T), \n",
    "                                                           rotation_labels)\n",
    "rotation_coefficients = lr_model_rotation.coef_.reshape(-1,1)\n",
    "theta_2 = rotation_coefficients / np.linalg.norm(rotation_coefficients)\n",
    "\n",
    "theta_2_theta_2_T = theta_2 @ theta_2.T\n",
    "\n",
    "I_minus_theta_1_theta_1_T_minus_theta_2_theta_2_T = I_minus_theta_1_theta_1_T - theta_2_theta_2_T\n",
    "\n",
    "# lr_model_blur = LogisticRegression(random_state=0).fit(Z_og_blurred @ \n",
    "#                                                        I_minus_theta_1_theta_1_T_minus_theta_2_theta_2_T, \n",
    "#                                                        blur_labels)\n",
    "# blur_coefficients = lr_model_blur.coef_.reshape(-1,1)\n",
    "# theta_3 = blur_coefficients / np.linalg.norm(blur_coefficients)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Contrast coefficients shape\")\n",
    "print(theta_1.shape)\n",
    "\n",
    "print('Train Contrast prediction accuracy: ', lr_model_contrast.score(Z_og_contrasted, contrast_labels))\n",
    "print('Test Contrast prediction accuracy: ', lr_model_contrast.score(Z_test_og_contrasted, t_mod_labels))\n",
    "print('Train rotation prediction accuracy: ', lr_model_rotation.score(Z_og_rotated, rotation_labels))\n",
    "# print('Train blur prediction accuracy: ', lr_model_blur.score(Z_og_blurred, blur_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Accuracies on extracted image features Z ( features obtained from the feature extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training Accuracy:  0.91304\n",
      "LR Accuracy on test data - Z - In Dist:  0.8953\n",
      "LR Accuracy on test data - Z - OOD:  0.1445\n"
     ]
    }
   ],
   "source": [
    "# Classification and recording prediction accuracy\n",
    "logistic_regression_model2 = LogisticRegression(\n",
    "    multi_class='multinomial', solver='lbfgs', random_state=0).fit(Z_train, \n",
    "                                                                   train_labels2)\n",
    "accuracy0 = logistic_regression_model2.score(Z_train, train_labels2)\n",
    "accuracy1 = logistic_regression_model2.score(Z_test_indist, test_labels2_indist)\n",
    "accuracy2 = logistic_regression_model2.score(Z_test_ood, test_labels2_ood)\n",
    "print('LR Training Accuracy: ', accuracy0)\n",
    "print('LR Accuracy on test data - Z - In Dist: ', accuracy1)\n",
    "print('LR Accuracy on test data - Z - OOD: ', accuracy2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find L, get F features, plot histograms and perform predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for lamda  0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training Accuracy - F:  0.90558\n",
      "LR Accuracy on test data - F - In Dist:  0.8901\n",
      "LR Accuracy on test data - F - OOD:  0.1506\n",
      "\n",
      "\n",
      "\n",
      "Accuracy for without F feature  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training Accuracy - F:  0.90346\n",
      "LR Accuracy on test data - F - In Dist:  0.8893\n",
      "LR Accuracy on test data - F - OOD:  0.1848\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Results for lamda  0.01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training Accuracy - F:  0.90454\n",
      "LR Accuracy on test data - F - In Dist:  0.8903\n",
      "LR Accuracy on test data - F - OOD:  0.1448\n",
      "\n",
      "\n",
      "\n",
      "Accuracy for without F feature  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training Accuracy - F:  0.90296\n",
      "LR Accuracy on test data - F - In Dist:  0.8897\n",
      "LR Accuracy on test data - F - OOD:  0.1895\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Results for lamda  10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training Accuracy - F:  0.87904\n",
      "LR Accuracy on test data - F - In Dist:  0.8674\n",
      "LR Accuracy on test data - F - OOD:  0.0724\n",
      "\n",
      "\n",
      "\n",
      "Accuracy for without F feature  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training Accuracy - F:  0.87488\n",
      "LR Accuracy on test data - F - In Dist:  0.8627\n",
      "LR Accuracy on test data - F - OOD:  0.1441\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Results for lamda  100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training Accuracy - F:  0.85578\n",
      "LR Accuracy on test data - F - In Dist:  0.8382\n",
      "LR Accuracy on test data - F - OOD:  0.0231\n",
      "\n",
      "\n",
      "\n",
      "Accuracy for without F feature  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training Accuracy - F:  0.84226\n",
      "LR Accuracy on test data - F - In Dist:  0.8257\n",
      "LR Accuracy on test data - F - OOD:  0.1619\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Results for lamda  100000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training Accuracy - F:  0.84902\n",
      "LR Accuracy on test data - F - In Dist:  0.8287\n",
      "LR Accuracy on test data - F - OOD:  0.0252\n",
      "\n",
      "\n",
      "\n",
      "Accuracy for without F feature  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training Accuracy - F:  0.82852\n",
      "LR Accuracy on test data - F - In Dist:  0.8118\n",
      "LR Accuracy on test data - F - OOD:  0.1978\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Results for lamda  1000000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training Accuracy - F:  0.8487\n",
      "LR Accuracy on test data - F - In Dist:  0.8281\n",
      "LR Accuracy on test data - F - OOD:  0.0247\n",
      "\n",
      "\n",
      "\n",
      "Accuracy for without F feature  0\n",
      "LR Training Accuracy - F:  0.8284\n",
      "LR Accuracy on test data - F - In Dist:  0.8117\n",
      "LR Accuracy on test data - F - OOD:  0.198\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/envs/invariance_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "# Computing M\n",
    "lamdas = [0.001,0.01,10,100,100000,1000000]\n",
    "\n",
    "for lamda in lamdas:\n",
    "    print(\"Results for lamda \", lamda)\n",
    "    print()\n",
    "    k = int(Z.shape[1]*0.5) # % of original number of features\n",
    "    n = Z.shape[0]\n",
    "    \n",
    "    delta_Z_matrix1 = np.absolute((Z_og_contrasted[:int(len(Z_og_contrasted)/2),:] - Z_og_contrasted[int(len(Z_og_contrasted)/2):,:]))\n",
    "    delta_Z_matrix2 = np.absolute((Z_og_rotated[:int(len(Z_og_rotated)/2),:] - Z_og_rotated[int(len(Z_og_rotated)/2):,:]))\n",
    "#     delta_Z_matrix3 = np.absolute((Z_og_blurred[:int(len(Z_og_blurred)/2),:] - Z_og_blurred[int(len(Z_og_blurred)/2):,:]))\n",
    "    \n",
    "    deltas_sum = lamda * delta_Z_matrix1.T @ delta_Z_matrix1 / (\n",
    "        n // 2 ) + lamda * delta_Z_matrix2.T @ delta_Z_matrix2 / (\n",
    "        n // 2 ) #+ lamda * delta_Z_matrix3.T @ delta_Z_matrix3 / (n // 2 ) \n",
    "    M = - Z.T @ Z/n + deltas_sum\n",
    "\n",
    "    # Computing the term on which we perform SVD\n",
    "    theta_1_theta_1_T = theta_1 @ theta_1.T\n",
    "    theta_2_theta_2_T = theta_2 @ theta_2.T\n",
    "#     theta_3_theta_3_T = theta_3 @ theta_3.T\n",
    "    d = theta_1_theta_1_T.shape[0]\n",
    "    I = np.identity(d)\n",
    "    I_minus_theta_theta_Ts_sum = I-theta_1_theta_1_T-theta_2_theta_2_T #-theta_3_theta_3_T\n",
    "    term_for_SVD = (I_minus_theta_theta_Ts_sum @ M) @ I_minus_theta_theta_Ts_sum\n",
    "\n",
    "\n",
    "    # Performing SVD to get eigenvectors and eigenvalues\n",
    "    from numpy import linalg as LA\n",
    "    eigenvalues, eigenvectors = LA.eigh(term_for_SVD)\n",
    "\n",
    "    # Forming L from eigenvectors and coeficients of transformations \n",
    "    L_1 = theta_1\n",
    "    L_2 = theta_2\n",
    "#     L_3 = theta_3\n",
    "    least_k_eigen_values = eigenvalues[:k]\n",
    "    least_k_eigen_values[np.absolute(least_k_eigen_values)<0.000001]=0\n",
    "\n",
    "    non_zero_indeces = None\n",
    "    if 0 in least_k_eigen_values:\n",
    "        non_zero_indeces = np.nonzero(least_k_eigen_values)[0]\n",
    "        least_k_eigen_values_without_0 = least_k_eigen_values[non_zero_indeces]\n",
    "\n",
    "    else:\n",
    "        non_zero_indeces = np.nonzero(least_k_eigen_values[:k-2])[0]\n",
    "        least_k_eigen_values_without_0 = least_k_eigen_values[:k-2]\n",
    "\n",
    "    L_3 = eigenvectors[:,non_zero_indeces]\n",
    "\n",
    "    L = np.concatenate((L_1,L_2,L_3), axis=1)\n",
    "\n",
    "   \n",
    "    # Obtaining F_test values from extracted image features using numpy's linalg.lstsq function.\n",
    "    F_train = torch.from_numpy(np.linalg.lstsq(L, Z_train.transpose(), rcond=None)[0].transpose())\n",
    "    F_test_indist = torch.from_numpy(np.linalg.lstsq(L, Z_test_indist.transpose(), rcond=None)[0].transpose())\n",
    "    F_test_ood = torch.from_numpy(np.linalg.lstsq(L, Z_test_ood.transpose(), rcond=None)[0].transpose())\n",
    "    F_test_original = torch.from_numpy(np.linalg.lstsq(L, Z_test_original.transpose(), rcond=None)[0].transpose())\n",
    "    F_test_contrasted = torch.from_numpy(np.linalg.lstsq(L, Z_test_contrasted.transpose(), rcond=None)[0].transpose())\n",
    "    \n",
    "\n",
    "    # Plot histograms\n",
    "\n",
    "    # the difference between F_test_green and F_test_red\n",
    "    delta_matrix = np.absolute(F_test_original.detach().numpy() - F_test_contrasted.detach().numpy())\n",
    "    delta_matrix_df = pd.DataFrame(delta_matrix)\n",
    "\n",
    "#     # Plotting the histograms for each feature in the delta matrix # 100 bins\n",
    "#     for i in range(10): #(len(delta_matrix_df.columns)): \n",
    "#         print(\"Histogram for F Test feature \", i)    \n",
    "#         feature = delta_matrix_df.iloc[:,i].values\n",
    "#         density = stats.gaussian_kde(feature)\n",
    "#         n, x, _ = plt.hist(feature, bins=np.linspace(0, np.amax(delta_matrix_df.iloc[:,0]), 100), \n",
    "#                            histtype='bar', density=True)  \n",
    "#         plt.plot(x, density(x))\n",
    "#         plt.show()\n",
    "    \n",
    "    \n",
    "    # Classification task using F features    \n",
    "    lr_model1 = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=0).fit(F_train,train_labels2)\n",
    "    accuracy0 = lr_model1.score(F_train, train_labels2)\n",
    "    accuracy1 = lr_model1.score(F_test_indist, test_labels2_indist)\n",
    "    accuracy2 = lr_model1.score(F_test_ood, test_labels2_ood)\n",
    "    print('LR Training Accuracy - F: ', accuracy0)\n",
    "    print('LR Accuracy on test data - F - In Dist: ', accuracy1)\n",
    "    print('LR Accuracy on test data - F - OOD: ', accuracy2)\n",
    "    print(\"\\n\"*2)\n",
    "\n",
    "    # Removing one feature at a time\n",
    "    for i in range(5): #(F_test_original.detach().numpy().shape[1]):\n",
    "        print(\"Accuracy for without F feature \",i)\n",
    "\n",
    "        X_train = F_train.detach().numpy().copy()\n",
    "        X_test_indist = F_test_indist.detach().numpy().copy()\n",
    "        X_test_ood = F_test_ood.detach().numpy().copy()\n",
    "\n",
    "#         X_train = np.delete(X_train, i, 1)\n",
    "#         X_test_indist = np.delete(X_test_indist, i, 1)\n",
    "#         X_test_ood = np.delete(X_test_ood, i, 1)\n",
    "\n",
    "        X_train = np.delete(X_train, 0, 1)\n",
    "        X_test_indist = np.delete(X_test_indist, 0, 1)\n",
    "        X_test_ood = np.delete(X_test_ood, 0, 1)\n",
    "        \n",
    "        X_train = np.delete(X_train, 0, 1)\n",
    "        X_test_indist = np.delete(X_test_indist, 0, 1)\n",
    "        X_test_ood = np.delete(X_test_ood, 0, 1)\n",
    "       \n",
    "\n",
    "        lr_model2 = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=0).fit(X_train,train_labels2)\n",
    "        accuracy0 = lr_model2.score(X_train, train_labels2)\n",
    "        accuracy1 = lr_model2.score(X_test_indist, test_labels2_indist)\n",
    "        accuracy2 = lr_model2.score(X_test_ood, test_labels2_ood)\n",
    "        print('LR Training Accuracy - F: ', accuracy0)\n",
    "        print('LR Accuracy on test data - F - In Dist: ', accuracy1)\n",
    "        print('LR Accuracy on test data - F - OOD: ', accuracy2)\n",
    "\n",
    "        print(\"\\n\"*1)\n",
    "        break\n",
    "    print(\"\\n\"*6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:invariance_env]",
   "language": "python",
   "name": "conda-env-invariance_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
